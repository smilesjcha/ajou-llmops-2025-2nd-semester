{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week02 - Advanced Reasoning Techniques\n",
    "\n",
    "ë³¸ ë…¸íŠ¸ë¶ì€ ê³ ê¸‰ ì¶”ë¡  í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•ë“¤ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ë‹¤ë£° ê¸°ë²•ë“¤\n",
    "1. **Zero-shot**: ì˜ˆì‹œ ì—†ì´ ì§ì ‘ ì¶”ë¡ \n",
    "2. **Few-shot**: ì†Œìˆ˜ ì˜ˆì‹œë¡œ íŒ¨í„´ í•™ìŠµ\n",
    "3. **Chain of Thought (CoT)**: ë‹¨ê³„ë³„ ì¶”ë¡ \n",
    "4. **Least-to-Most**: ë¬¸ì œ ë¶„í•´ í›„ ìˆœì°¨ í•´ê²°\n",
    "5. **Tree of Thoughts (ToT)**: ë‹¤ì¤‘ ê²½ë¡œ íƒìƒ‰\n",
    "6. **ReAct**: ì¶”ë¡ ê³¼ í–‰ë™ì˜ ë°˜ë³µ\n",
    "7. **Program-Aided Language Model (PAL)**: ì½”ë“œë¥¼ í†µí•œ ì •í™•í•œ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° import\n",
    "import subprocess\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import functools\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError:\n",
    "    !pip install openai\n",
    "    from openai import OpenAI\n",
    "\n",
    "# ì„¤ì •\n",
    "client = OpenAI()  # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ìë™ ë¡œë“œ\n",
    "\n",
    "# í—¬í¼ í•¨ìˆ˜ë“¤\n",
    "def run_ollama(model: str, prompt: str) -> str:\n",
    "    \"\"\"Ollama ëª¨ë¸ ì‹¤í–‰\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model],\n",
    "            input=prompt,\n",
    "            text=True,\n",
    "            capture_output=True,\n",
    "            timeout=60\n",
    "        )\n",
    "        return result.stdout.strip()\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"Error: Timeout\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def run_openai(prompt: str, model: str = \"gpt-5-mini\", **kwargs) -> str:\n",
    "    \"\"\"OpenAI ëª¨ë¸ ì‹¤í–‰\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            **kwargs\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def run_openai_with_messages(messages: List[Dict], model: str = \"gpt-5-mini\", **kwargs) -> str:\n",
    "    \"\"\"OpenAI ëª¨ë¸ ì‹¤í–‰ (ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©)\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            **kwargs\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Zero-shot\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: ì˜ˆì‹œ ì—†ì´ ë¬¸ì œÂ·ì¶œë ¥ í¬ë§·ë§Œìœ¼ë¡œ ë‹µì„ ì–»ìŒ\n",
    "\n",
    "- ì¥ì : ì¤€ë¹„ ë¹„ìš©â†“, ì¼ë°˜í™” í…ŒìŠ¤íŠ¸ì— ìœ ë¦¬\n",
    "- ë‹¨ì : í¬ë§· ì¼íƒˆÂ·ê³¼ì‰ì°½ì‘ ìœ„í—˜\n",
    "- ì„¤ê³„ íŒ: \"**ì—­í• ** + **íƒœìŠ¤í¬** + **ì¶œë ¥ ìŠ¤í‚¤ë§ˆ/ì œì•½**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot ê°ì„± ë¶„ë¥˜ ===\n",
      "Ollama (llama3.1:8b):\n",
      "```\n",
      "{\n",
      "  \"label\": \"positive\",\n",
      "  \"reason\": \"Expresses satisfaction with fast delivery and good packaging\"\n",
      "}\n",
      "```\n",
      "\n",
      "OpenAI (gpt-5-mini):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Zero-shot - ê³ ê° ë¦¬ë·° ê°ì„± ë¶„ë¥˜\n",
    "zero_shot_prompt = \"\"\"Role: sentiment classifier.\n",
    "Task: Classify review as positive|negative|neutral and give a one-line reason.\n",
    "Return ONLY JSON {label, reason}.\n",
    "Review: --- ë°°ì†¡ ë¹ ë¥´ê³  í¬ì¥ ê¹”ë”, ì¬êµ¬ë§¤ ì˜ì‚¬ ìˆì–´ìš” ---\"\"\"\n",
    "\n",
    "print(\"=== Zero-shot ê°ì„± ë¶„ë¥˜ ===\")\n",
    "print(\"Ollama (llama3.1:8b):\")\n",
    "zero_shot_ollama = run_ollama(\"llama3.1:8b\", zero_shot_prompt)\n",
    "print(zero_shot_ollama)\n",
    "\n",
    "print(\"\\nOpenAI (gpt-5-mini):\")\n",
    "zero_shot_openai = run_openai(zero_shot_prompt, max_completion_tokens=120)\n",
    "print(zero_shot_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot ë‹¤ì–‘í•œ ì˜ˆì‹œ í…ŒìŠ¤íŠ¸ ===\n",
      "ì˜ˆì‹œ 1: ë°°ì†¡ì´ ëŠ¦ê³  í¬ì¥ë„ ì°¢ì–´ì¡Œì–´ìš”\n",
      "ê²°ê³¼: \n",
      "\n",
      "ì˜ˆì‹œ 2: ê°€ê²©ì€ ë¹„ì‹¸ì§€ë§Œ í’ˆì§ˆì´ ì¢‹ë„¤ìš”\n",
      "ê²°ê³¼: \n",
      "\n",
      "ì˜ˆì‹œ 3: ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤. íŠ¹ë³„í•˜ì§€ ì•Šì•„ìš”\n",
      "ê²°ê³¼: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot ë‹¤ë¥¸ ì˜ˆì‹œë“¤\n",
    "zero_shot_examples = [\n",
    "    \"ë°°ì†¡ì´ ëŠ¦ê³  í¬ì¥ë„ ì°¢ì–´ì¡Œì–´ìš”\",\n",
    "    \"ê°€ê²©ì€ ë¹„ì‹¸ì§€ë§Œ í’ˆì§ˆì´ ì¢‹ë„¤ìš”\",\n",
    "    \"ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤. íŠ¹ë³„í•˜ì§€ ì•Šì•„ìš”\"\n",
    "]\n",
    "\n",
    "print(\"=== Zero-shot ë‹¤ì–‘í•œ ì˜ˆì‹œ í…ŒìŠ¤íŠ¸ ===\")\n",
    "for i, review in enumerate(zero_shot_examples, 1):\n",
    "    prompt = f\"\"\"Role: sentiment classifier.\n",
    "Task: Classify review as positive|negative|neutral and give a one-line reason.\n",
    "Return ONLY JSON {{label, reason}}.\n",
    "Review: --- {review} ---\"\"\"\n",
    "    \n",
    "    result = run_openai(prompt, max_completion_tokens=100)\n",
    "    print(f\"ì˜ˆì‹œ {i}: {review}\")\n",
    "    print(f\"ê²°ê³¼: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Few-shot\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: ì†Œìˆ˜ ì˜ˆì‹œë¡œ ì˜ë„Â·í¬ë§·ì„ í•™ìŠµ ìœ ë„\n",
    "\n",
    "- ì¥ì : í¬ë§· ì•ˆì •í™”Â·ê²½ê³„ ì¼€ì´ìŠ¤ êµì •\n",
    "- ë‹¨ì : ë°ì´í„° ëˆ„ìˆ˜/í¸í–¥Â·ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©ëŸ‰â†‘\n",
    "- ì„¤ê³„ íŒ: \"ì¢‹ì€/ë‚˜ìœ\" ì˜ˆì‹œë¥¼ ëŒ€ì¡°ë¡œ ë°°ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Few-shot ì˜ë„ ë¶„ë¥˜ ===\n",
      "Ollama:\n",
      "A nice example!\n",
      "\n",
      "Based on the context of the sentence, I would classify it as:\n",
      "\n",
      "{\"intent\": \"exchange\"}\n",
      "\n",
      "The reason is that the customer is complaining about a discrepancy between the color in the picture and the actual product, which implies they want to exchange the item for one with the correct color. The phrase \"ë°”ê¿€ ìˆ˜ ìˆë‚˜ìš”?\" (Can I change/replace it?) further supports this interpretation.\n",
      "\n",
      "Am I correct?\n",
      "\n",
      "OpenAI:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Few-shot - ì£¼ë¬¸ ì˜ë„ ë¶„ë¥˜\n",
    "few_shot_prompt = \"\"\"Task: intent classification -> refund|exchange|question. JSON {intent}.\n",
    "Examples:\n",
    "- 'ê°œë´‰ ì „ì¸ë° í™˜ë¶ˆ ì›í•´ìš”' -> {\"intent\": \"refund\"}\n",
    "- 'ì‚¬ì´ì¦ˆ ì•ˆ ë§ì•„ êµí™˜í• ë˜ìš”' -> {\"intent\": \"exchange\"}\n",
    "- 'ë°°ì†¡ ì–¸ì œ ì˜¤ë‚˜ìš”?' -> {\"intent\": \"question\"}\n",
    "Now classify: --- ìƒ‰ìƒì´ ì‚¬ì§„ê³¼ ë‹¬ë¼ìš”, ë°”ê¿€ ìˆ˜ ìˆë‚˜ìš”? ---\"\"\"\n",
    "\n",
    "print(\"=== Few-shot ì˜ë„ ë¶„ë¥˜ ===\")\n",
    "print(\"Ollama:\")\n",
    "few_shot_ollama = run_ollama(\"llama3.1:8b\", few_shot_prompt)\n",
    "print(few_shot_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "few_shot_openai = run_openai(few_shot_prompt, max_completion_tokens=80)\n",
    "print(few_shot_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Zero-shot vs Few-shot ì„±ëŠ¥ ë¹„êµ ===\n",
      "\n",
      "ì…ë ¥: ë¶ˆëŸ‰í’ˆì´ë¼ì„œ ëˆ ëŒë ¤ë°›ê³  ì‹¶ì–´ìš”\n",
      "Zero-shot: \n",
      "Few-shot: \n",
      "\n",
      "ì…ë ¥: ë‹¤ë¥¸ ìƒ‰ê¹”ë¡œ ë°”ê¿”ì£¼ì„¸ìš”\n",
      "Zero-shot: \n",
      "Few-shot: \n",
      "\n",
      "ì…ë ¥: ì–¸ì œê¹Œì§€ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?\n",
      "Zero-shot: \n",
      "Few-shot: \n"
     ]
    }
   ],
   "source": [
    "# Few-shot ì„±ëŠ¥ ë¹„êµ: Zero-shot vs Few-shot\n",
    "test_inputs = [\n",
    "    \"ë¶ˆëŸ‰í’ˆì´ë¼ì„œ ëˆ ëŒë ¤ë°›ê³  ì‹¶ì–´ìš”\",\n",
    "    \"ë‹¤ë¥¸ ìƒ‰ê¹”ë¡œ ë°”ê¿”ì£¼ì„¸ìš”\",\n",
    "    \"ì–¸ì œê¹Œì§€ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "print(\"=== Zero-shot vs Few-shot ì„±ëŠ¥ ë¹„êµ ===\")\n",
    "\n",
    "for text in test_inputs:\n",
    "    print(f\"\\nì…ë ¥: {text}\")\n",
    "    \n",
    "    # Zero-shot\n",
    "    zero_prompt = f\"Classify customer intent -> refund|exchange|question. JSON only.\\nText: {text}\"\n",
    "    zero_result = run_openai(zero_prompt, max_completion_tokens=50)\n",
    "    print(f\"Zero-shot: {zero_result}\")\n",
    "    \n",
    "    # Few-shot  \n",
    "    few_prompt = f\"\"\"Examples:\n",
    "- 'í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”' -> {{\"intent\": \"refund\"}}\n",
    "- 'êµí™˜ ê°€ëŠ¥í•œê°€ìš”?' -> {{\"intent\": \"exchange\"}}\n",
    "- 'ë°°ì†¡ ì •ë³´ ì•Œë ¤ì£¼ì„¸ìš”' -> {{\"intent\": \"question\"}}\n",
    "Classify: {text}\"\"\"\n",
    "    few_result = run_openai(few_prompt, max_completion_tokens=50)\n",
    "    print(f\"Few-shot: {few_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chain of Thought (CoT)\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ìœ ë„í•´ ì˜¤ë¥˜ìœ¨â†“\n",
    "\n",
    "- ì¥ì : ë³µì¡ ì‚°ìˆ Â·ë…¼ë¦¬Â·ê³„íš ë¬¸ì œì— ê°•í•¨\n",
    "- ì„¤ê³„ íŒ: \"ë‹¨ê³„ë³„ë¡œ ì‚¬ê³ í•˜ë˜, ë§ˆì§€ë§‰ì— 'ì •ë‹µë§Œ' ë³„ë„ í‘œê¸°\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CoT ìˆ˜í•™ ë¬¸ì œ ===\n",
      "Ollama:\n",
      "Here is the solution:\n",
      "\n",
      "{\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"operator\": \"*\",\n",
      "      \"operands\": [\n",
      "        {\n",
      "          \"value\": 30,\n",
      "          \"digits\": [\"3\", \"0\"]\n",
      "        },\n",
      "        {\n",
      "          \"value\": 20,\n",
      "          \"digits\": [\"2\", \"0\"]\n",
      "        }\n",
      "      ],\n",
      "      \"result\": {\n",
      "        \"value\": 600,\n",
      "        \"digits\": [\"6\", \"0\", \"0\"]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"operator\": \"*\",\n",
      "      \"operands\": [\n",
      "        {\n",
      "          \"value\": 10,\n",
      "          \"digits\": [\"1\", \"0\"]\n",
      "        },\n",
      "        {\n",
      "          \"value\": 20,\n",
      "          \"digits\": [\"2\", \"0\"]\n",
      "        }\n",
      "      ],\n",
      "      \"result\": {\n",
      "        \"value\": 200,\n",
      "        \"digits\": [\"2\", \"0\", \"0\"]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"operator\": \"+\",\n",
      "      \"operands\": [\n",
      "        {\n",
      "          \"value\": 600,\n",
      "          \"digits\": [\"6\", \"0\", \"0\"]\n",
      "        },\n",
      "        {\n",
      "          \"value\": 200,\n",
      "          \"digits\": [\"2\", \"0\", \"0\"]\n",
      "        }\n",
      "      ],\n",
      "      \"result\": {\n",
      "        \"value\": 800,\n",
      "        \"digits\": [\"8\", \"0\", \"0\"]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"final_answer\": 800\n",
      "}\n",
      "\n",
      "OpenAI:\n",
      "\n",
      "\n",
      "ì‹¤ì œ ì •ë‹µ: 1702\n"
     ]
    }
   ],
   "source": [
    "# 3. Chain of Thought - ìˆ˜í•™ ë¬¸ì œ\n",
    "cot_math_prompt = \"\"\"Solve step by step. Provide JSON:\n",
    "{\"steps\": [...], \"final_answer\": number}\n",
    "Q: 37 * 46\"\"\"\n",
    "\n",
    "print(\"=== CoT ìˆ˜í•™ ë¬¸ì œ ===\")\n",
    "print(\"Ollama:\")\n",
    "cot_math_ollama = run_ollama(\"llama3.1:8b\", cot_math_prompt)\n",
    "print(cot_math_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "cot_math_openai = run_openai(cot_math_prompt, max_completion_tokens=250)\n",
    "print(cot_math_openai)\n",
    "\n",
    "# ì •ë‹µ í™•ì¸\n",
    "print(f\"\\nì‹¤ì œ ì •ë‹µ: {37 * 46}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CoT ë…¼ë¦¬ ì¶”ë¡  ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CoT ë…¼ë¦¬ ì¶”ë¡  ë¬¸ì œ\n",
    "cot_logic_prompt = \"\"\"Think step by step and provide your reasoning.\n",
    "Problem: ëª¨ë“  ê³ ì–‘ì´ëŠ” ë™ë¬¼ì´ë‹¤. ì†œì´ëŠ” ê³ ì–‘ì´ë‹¤. ë”°ë¼ì„œ ì†œì´ëŠ” ë™ë¬¼ì´ë‹¤.\n",
    "ì´ ë…¼ì¦ì˜ ìœ íš¨ì„±ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ê³  JSONìœ¼ë¡œ ë‹µí•˜ì‹œì˜¤:\n",
    "{\"steps\": [...], \"conclusion\": \"valid|invalid\", \"reason\": \"...\"}\"\"\"\n",
    "\n",
    "print(\"=== CoT ë…¼ë¦¬ ì¶”ë¡  ===\")\n",
    "cot_logic_result = run_openai(cot_logic_prompt, max_completion_tokens=300)\n",
    "print(cot_logic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CoT vs ì§ì ‘ ë‹µë³€ ë¹„êµ ===\n",
      "ì§ì ‘ ë‹µë³€: \n",
      "\n",
      "CoT ë‹µë³€: \n",
      "\n",
      "ë¬¸ì œ í•´ì„ì— ë”°ë¥¸ ì •ë‹µ:\n",
      "í•´ì„1 (ëª¨ë“  ì‚¬ê³¼ë¥¼ ë‚˜ëˆ„ì–´ì¤Œ): 24-24+0-3 = -3 (ë¶ˆê°€ëŠ¥)\n",
      "í•´ì„2 (4ëª…ì´ì„œ ë‚˜ëˆ„ì–´ ë¨¹ìŒ): 24/4=6, 6-3=3ê°œ ë‚¨ìŒ\n"
     ]
    }
   ],
   "source": [
    "# CoT vs ì§ì ‘ ë‹µë³€ ë¹„êµ\n",
    "word_problem = \"Sarahê°€ ì‚¬ê³¼ 24ê°œë¥¼ ê°€ì§€ê³  ìˆë‹¤. ì¹œêµ¬ 3ëª…ì—ê²Œ ë˜‘ê°™ì´ ë‚˜ëˆ„ì–´ì£¼ê³ , ìì‹ ì€ 3ê°œë¥¼ ë” ë¨¹ì—ˆë‹¤. ë‚¨ì€ ì‚¬ê³¼ëŠ” ëª‡ ê°œì¸ê°€?\"\n",
    "\n",
    "print(\"=== CoT vs ì§ì ‘ ë‹µë³€ ë¹„êµ ===\")\n",
    "\n",
    "# ì§ì ‘ ë‹µë³€\n",
    "direct_prompt = f\"ë¬¸ì œ: {word_problem}\\në‹µ:\"\n",
    "direct_result = run_openai(direct_prompt, max_completion_tokens=100)\n",
    "print(f\"ì§ì ‘ ë‹µë³€: {direct_result}\")\n",
    "\n",
    "# CoT ë‹µë³€\n",
    "cot_prompt = f\"\"\"ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í•´ê²°í•˜ì„¸ìš”.\n",
    "JSON í˜•ì‹: {{\"steps\": [...], \"final_answer\": number}}\n",
    "ë¬¸ì œ: {word_problem}\"\"\"\n",
    "cot_result = run_openai(cot_prompt, max_completion_tokens=200)\n",
    "print(f\"\\nCoT ë‹µë³€: {cot_result}\")\n",
    "\n",
    "# ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ ì •ë‹µ í™•ì¸\n",
    "# Sarah 24ê°œ -> ì¹œêµ¬ 3ëª…ì—ê²Œ ë‚˜ëˆ„ì–´ì¤Œ (24/3 = 8ê°œì”©) -> 24-24 = 0ê°œ\n",
    "# ì•„ë‹ˆë©´ Sarahê°€ ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ 4ëª…ì´ì„œ ë‚˜ëˆ„ì–´ ë¨¹ëŠ”ë‹¤ëŠ” ì˜ë¯¸ì¼ ìˆ˜ë„: 24/4 = 6ê°œì”©\n",
    "# Sarahê°€ 3ê°œ ë” ë¨¹ìŒ -> 6-3 = 3ê°œ ë‚¨ìŒ\n",
    "print(\"\\në¬¸ì œ í•´ì„ì— ë”°ë¥¸ ì •ë‹µ:\")\n",
    "print(\"í•´ì„1 (ëª¨ë“  ì‚¬ê³¼ë¥¼ ë‚˜ëˆ„ì–´ì¤Œ): 24-24+0-3 = -3 (ë¶ˆê°€ëŠ¥)\")\n",
    "print(\"í•´ì„2 (4ëª…ì´ì„œ ë‚˜ëˆ„ì–´ ë¨¹ìŒ): 24/4=6, 6-3=3ê°œ ë‚¨ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Least-to-Most\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: ë¬¸ì œë¥¼ ì‘ì€ í•˜ìœ„ë¬¸ì œë¡œ ë¶„í•´ â†’ ìˆœì„œëŒ€ë¡œ í•´ê²°\n",
    "\n",
    "- ì¥ì : ì¥ë¬¸ ì¶”ë¡ , ì œì•½ ì¶©ëŒ í•´ê²°ì— ìœ ë¦¬\n",
    "- ì„¤ê³„ í…œí”Œë¦¿: 1) í•˜ìœ„ëª©í‘œ ë‚˜ì—´ 2) ê° ëª©í‘œ í•´ê²° 3) ìµœì¢… í†µí•© ë‹µ ì‚°ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Least-to-Most ì ì‹¬ ì¶”ì²œ ===\n",
      "Ollama:\n",
      "ì˜ˆì‚° 10ë§Œì›, 3ëª…, ë¹„ê±´ 1ëª…ì„ ìœ„í•œ ì ì‹¬ ì½”ìŠ¤ ì¶”ì²œ (2ê³³)ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í•´ê²°ì±…ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "| ì‹ë‹¹ | ì¸ë‹¹ê°€ê²© | ì´ì•¡ | ë¹„ê±´ì˜µì…˜ | íŠ¹ì§• |\n",
      "| --- | --- | --- | --- | --- |\n",
      "| ê°€ | 30,000ì›/ì¸ | 90,000ì› | â˜•ï¸ | ì£¼ë§ì—ë§Œ ìš´ì˜ |\n",
      "| ë‚˜ | 25,000ì›/ì¸ | 75,000ì› | ğŸŒ± | ë¹„ê±´ ì‹ë‹¹ |\n",
      "\n",
      "**í•´ê²° ë°©ë²•**\n",
      "\n",
      "1. **í•˜ìœ„ëª©í‘œ**: \n",
      "    - ë¹„ìš©: 10ë§Œì› ì´ë‚´\n",
      "    - ì¸ì›: 3ëª… (ë¹„ê±´ 1ëª…)\n",
      "    - ì ì‹¬ ì½”ìŠ¤ ì¶”ì²œ (2ê³³)\n",
      "\n",
      "2. **ê° ëª©í‘œ í•´ê²°**\n",
      "   - **ì‹ë‹¹ 1:** ê°€\n",
      "     - ê°€ê²©: 30,000ì›/ì¸\n",
      "     - ì´ ë¹„ìš©: 90,000ì›\n",
      "     - ë¹„ê±´ ì˜µì…˜: â˜•ï¸\n",
      "     - íŠ¹ì§•: ì£¼ë§ì—ë§Œ ìš´ì˜\n",
      "\n",
      "   - **ì‹ë‹¹ 2:** ë‚˜\n",
      "     - ê°€ê²©: 25,000ì›/ì¸\n",
      "     - ì´ ë¹„ìš©: 75,000ì›\n",
      "     - ë¹„ê±´ ì˜µì…˜: ğŸŒ±\n",
      "     - íŠ¹ì§•: ë¹„ê±´ ì‹ë‹¹\n",
      "\n",
      "3. **í†µí•© ì†”ë£¨ì…˜**\n",
      "   - ë‘ ì‹ë‹¹ ì¤‘ì—ì„œ ì¸ë‹¹ ê°€ê²©ì´ ì €ë ´í•˜ê³  ë¹„ê±´ ì˜µì…˜ì´ ìˆëŠ” ë‚˜ ì‹ë‹¹ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "   - ì´ ë¹„ìš©ì€ 75,000ì›ìœ¼ë¡œ 10ë§Œì› ì´ë‚´ì— ì ì‹¬ ì½”ìŠ¤ë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê²°ê³¼ì ìœ¼ë¡œ ë‚˜ ì‹ë‹¹ (ë¹„ê±´ ì˜µì…˜)ìœ¼ë¡œ ë¹„ìš©ì€ 90,000ì›ì—ì„œ 75,000ì›ìœ¼ë¡œ ì¤„ì–´ë“  ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "=== OpenAI ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Least-to-Most - ë³µí•© ì œì•½ ë¬¸ì œ\n",
    "ltm_prompt = \"\"\"Use least-to-most decomposition.\n",
    "Problem: ì˜ˆì‚° 10ë§Œì›, 3ëª…, ë¹„ê±´ 1ëª…ì„ ìœ„í•œ ì ì‹¬ ì½”ìŠ¤ ì¶”ì²œ (2ê³³), ì´ì•¡â‰¤10ë§Œì›\n",
    "\n",
    "Step 1: í•˜ìœ„ëª©í‘œ ë‚˜ì—´\n",
    "Step 2: ê° ëª©í‘œ í•´ê²°  \n",
    "Step 3: í†µí•© ì†”ë£¨ì…˜\n",
    "\n",
    "Return markdown table: | ì‹ë‹¹ | ì¸ë‹¹ê°€ê²© | ì´ì•¡ | ë¹„ê±´ì˜µì…˜ | íŠ¹ì§• |\"\"\"\n",
    "\n",
    "print(\"=== Least-to-Most ì ì‹¬ ì¶”ì²œ ===\")\n",
    "print(\"Ollama:\")\n",
    "ltm_ollama = run_ollama(\"llama3.1:8b\", ltm_prompt)\n",
    "print(ltm_ollama)\n",
    "\n",
    "print(\"\\n=== OpenAI ===\")\n",
    "ltm_openai = run_openai(ltm_prompt, max_completion_tokens=400)\n",
    "print(ltm_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Least-to-Most í”„ë¡œì íŠ¸ ê³„íš ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Least-to-Most í”„ë¡œì íŠ¸ ê³„íš\n",
    "ltm_project_prompt = \"\"\"Use least-to-most approach to create a project plan.\n",
    "Goal: \"ì›¹ì‚¬ì´íŠ¸ ë¦¬ë‰´ì–¼ í”„ë¡œì íŠ¸ (4ì£¼, íŒ€ 5ëª…, ì˜ˆì‚° 500ë§Œì›)\"\n",
    "\n",
    "1) ì£¼ìš” í•˜ìœ„ ì‘ì—…ë“¤ì„ ì‹ë³„\n",
    "2) ê° ì‘ì—…ì˜ ë¦¬ì†ŒìŠ¤ì™€ ì‹œê°„ í• ë‹¹\n",
    "3) ìµœì¢… í†µí•© ê³„íší‘œ ì‘ì„±\n",
    "\n",
    "Output format: JSON with {\"subtasks\": [...], \"timeline\": {...}, \"final_plan\": \"...\"}\"\"\"\n",
    "\n",
    "print(\"=== Least-to-Most í”„ë¡œì íŠ¸ ê³„íš ===\")\n",
    "ltm_project_result = run_openai(ltm_project_prompt, max_completion_tokens=500)\n",
    "print(ltm_project_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tree of Thoughts (ToT)\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: ì—¬ëŸ¬ ì¶”ë¡  ê²½ë¡œ(ìƒê° ê°€ì§€) ìƒì„± â†’ ìì²´í‰ê°€ í›„ ìµœê³ ì•ˆ ì„ íƒ\n",
    "\n",
    "- ì¥ì : íƒìƒ‰ì  ë¬¸ì œ(ê¸°íšÂ·ì „ëµÂ·ì„¤ê³„)ì— ê°•í•¨\n",
    "- ì„¤ê³„ í…œí”Œë¦¿: ê°€ì§€ ìƒì„± N(ë³´í†µ 3) â†’ ê° ê°€ì§€ ì¥ë‹¨ì  í‰ê°€ â†’ ìµœì¢… ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tree of Thoughts í•™ìŠµ ì „ëµ ===\n",
      "Ollama:\n",
      "Here are three distinct study plans using the Tree of Thoughts approach to achieve a balanced 4-week study strategy for high school students in math, English, and science:\n",
      "\n",
      "**Plan 1: Intensive Focus**\n",
      "\n",
      "* **Approach:** Divide the 4 weeks into four main topics (2 in math, 1 in English, 1 in science). Each week, focus on one topic exclusively, allocating 70% of study time to it.\n",
      "* **Pros:**\n",
      "\t+ Deep understanding of each topic\n",
      "\t+ Improved retention and recall\n",
      "\t+ Time management skills development\n",
      "* **Cons:**\n",
      "\t+ Risk of neglecting other important topics\n",
      "\t+ Limited exposure to different subjects\n",
      "\t+ Potential burnout due to intense focus on one topic\n",
      "* **Rating:** 7/10\n",
      "\n",
      "**Plan 2: Balanced Approach**\n",
      "\n",
      "* **Approach:** Divide the 4 weeks into four equal parts, allocating 30% of study time to each subject. Rotate topics within each subject area (e.g., algebra and geometry in math).\n",
      "* **Pros:**\n",
      "\t+ Better balance between subjects\n",
      "\t+ Reduced risk of neglecting important topics\n",
      "\t+ Improved overall understanding of multiple subjects\n",
      "* **Cons:**\n",
      "\t+ May not allow for deep dives into individual topics\n",
      "\t+ Requires more time management skills to rotate topics effectively\n",
      "* **Rating:** 8.5/10\n",
      "\n",
      "**Plan 3: Priority-Based Study**\n",
      "\n",
      "* **Approach:** Prioritize topics based on upcoming exams, quizzes, or project deadlines. Allocate study time accordingly (80% for high-priority topics, 20% for low-priority ones).\n",
      "* **Pros:**\n",
      "\t+ Effective use of limited study time\n",
      "\t+ Reduced stress due to targeted focus on critical topics\n",
      "\t+ Improved grades and performance in important assessments\n",
      "* **Cons:**\n",
      "\t+ May lead to neglect of other important topics\n",
      "\t+ Requires frequent adjustments based on changing priorities\n",
      "* **Rating:** 8/10\n",
      "\n",
      "**Best Plan:** \"Balanced Approach\" (Plan 2)\n",
      "\n",
      "Reason: This plan strikes a balance between focus and breadth, allowing for deep understanding of individual topics while also ensuring that all subjects receive sufficient attention.\n",
      "\n",
      "=== OpenAI ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Tree of Thoughts - í•™ìŠµ ì „ëµ\n",
    "tot_prompt = \"\"\"Generate 3 distinct study plans using Tree of Thoughts.\n",
    "Goal: \"ê³ ë“±í•™ìƒì„ ìœ„í•œ 4ì£¼ ê³µë¶€ì „ëµ(ìˆ˜í•™Â·ì˜ì–´Â·ê³¼í•™ ê· í˜•)\"\n",
    "\n",
    "For each plan:\n",
    "1) Outline the approach\n",
    "2) List pros and cons\n",
    "3) Rate effectiveness (1-10)\n",
    "\n",
    "Finally, pick BEST plan with 1-line rationale.\n",
    "\n",
    "Return JSON: {\"plans\": [{\"name\": \"...\", \"outline\": \"...\", \"pros\": [...], \"cons\": [...], \"rating\": N}], \"best_choice\": {\"name\": \"...\", \"reason\": \"...\"}}\"\"\"\n",
    "\n",
    "print(\"=== Tree of Thoughts í•™ìŠµ ì „ëµ ===\")\n",
    "print(\"Ollama:\")\n",
    "tot_ollama = run_ollama(\"llama3.1:8b\", tot_prompt)\n",
    "print(tot_ollama)\n",
    "\n",
    "print(\"\\n=== OpenAI ===\")\n",
    "tot_openai = run_openai(tot_prompt, max_completion_tokens=700)\n",
    "print(tot_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tree of Thoughts ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ToT ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ\n",
    "tot_business_prompt = \"\"\"Tree of Thoughts for business strategy.\n",
    "Challenge: \"ìŠ¤íƒ€íŠ¸ì—…ì˜ ì²« ì œí’ˆ ì¶œì‹œ ì „ëµ (B2B SaaS)\"\n",
    "\n",
    "Generate 3 different approaches:\n",
    "1) ê° ì ‘ê·¼ë²•ì˜ í•µì‹¬ ì•„ì´ë””ì–´\n",
    "2) ì˜ˆìƒ ë¹„ìš©ê³¼ ì‹œê°„\n",
    "3) ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒìš”ì¸\n",
    "4) ì„±ê³µ ê°€ëŠ¥ì„± í‰ê°€\n",
    "\n",
    "Choose the best strategy and explain why.\"\"\"\n",
    "\n",
    "print(\"=== Tree of Thoughts ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ===\")\n",
    "tot_business_result = run_openai(tot_business_prompt, max_completion_tokens=600)\n",
    "print(tot_business_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ReAct (Reasoning + Acting)\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: Reason(ì¶”ë¡ ) + Action(íˆ´ í˜¸ì¶œ) + Observation(ê²°ê³¼ ë°˜ì˜) ë£¨í”„\n",
    "\n",
    "- ì¥ì : ì‹¤ì‹œê°„ ë°ì´í„°/DB/ê³„ì‚°ê³¼ ê²°í•©\n",
    "- ì„¤ê³„ íŒ: íˆ´ ìŠ¤í‚¤ë§ˆ(ì´ë¦„/íŒŒë¼ë¯¸í„°/ì„¤ëª…) ëª…í™•íˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 11) (615955541.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mNow do this pattern for: \"ì˜¤ëŠ˜ ë‹¬ëŸ¬ í™˜ìœ¨ í™•ì¸í•˜ê³  íˆ¬ì ì¡°ì–¸ í•œ ì¤„\"\"\"\"\u001b[39m\n                                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 11)\n"
     ]
    }
   ],
   "source": [
    "# 6. ReAct - ì‹œë®¬ë ˆì´ì…˜ (OllamaëŠ” íˆ´ í˜¸ì¶œ ë¯¸ì§€ì›ì´ë¯€ë¡œ í…ìŠ¤íŠ¸ë¡œ í‰ë‚´)\n",
    "react_simulation_prompt = \"\"\"Follow ReAct pattern (Reasoning + Action + Observation).\n",
    "Task: \"ë‚´ì¼ ì„œìš¸ ë‚ ì”¨ë¥¼ í™•ì¸í•˜ê³  í•œ ì¤„ ìš”ì•½í•´ì¤˜\"\n",
    "\n",
    "Thought: I should check the weather for Seoul tomorrow.\n",
    "Action: get_weather(city='Seoul', date='tomorrow')\n",
    "Observation: (simulate) 'Sunny, 27Â°C, light breeze'\n",
    "Thought: Now I can provide a summary.\n",
    "Final Answer: ë‚´ì¼ ì„œìš¸ì€ ë§‘ê³  27ë„ë¡œ ì¾Œì í•œ ë‚ ì”¨ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.\n",
    "\n",
    "Now do this pattern for: \"ì˜¤ëŠ˜ ë‹¬ëŸ¬ í™˜ìœ¨ í™•ì¸í•˜ê³  íˆ¬ì ì¡°ì–¸ í•œ ì¤„\"\"\"\"\n",
    "\n",
    "print(\"=== ReAct ì‹œë®¬ë ˆì´ì…˜ ===\")\n",
    "print(\"Ollama:\")\n",
    "react_ollama = run_ollama(\"llama3.1:8b\", react_simulation_prompt)\n",
    "print(react_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "react_openai = run_openai(react_simulation_prompt, max_completion_tokens=300)\n",
    "print(react_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct ì‹¤ì œ Function Calling (OpenAI)\n",
    "# ì‹¤ì œ ë„êµ¬ ì •ì˜\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"ë”ë¯¸ ë‚ ì”¨ API\"\"\"\n",
    "    weather_data = {\n",
    "        \"ì„œìš¸\": \"ë§‘ìŒ, 25ë„\",\n",
    "        \"ë¶€ì‚°\": \"íë¦¼, 28ë„\", \n",
    "        \"Seoul\": \"Sunny, 25Â°C\"\n",
    "    }\n",
    "    return weather_data.get(city, \"ë‚ ì”¨ ì •ë³´ ì—†ìŒ\")\n",
    "\n",
    "def calculate_math(expression: str) -> str:\n",
    "    \"\"\"ì•ˆì „í•œ ìˆ˜ì‹ ê³„ì‚°\"\"\"\n",
    "    try:\n",
    "        # ì•ˆì „í•œ ìˆ˜ì‹ë§Œ ê³„ì‚° (eval ëŒ€ì‹  ê°„ë‹¨í•œ íŒŒì‹±)\n",
    "        if re.match(r'^[0-9+\\-*/().\\s]+$', expression):\n",
    "            result = eval(expression)  # ì‹¤ì œë¡œëŠ” ë” ì•ˆì „í•œ íŒŒì„œ ì‚¬ìš© ê¶Œì¥\n",
    "            return str(result)\n",
    "        else:\n",
    "            return \"ì§€ì›ë˜ì§€ ì•ŠëŠ” ìˆ˜ì‹\"\n",
    "    except:\n",
    "        return \"ê³„ì‚° ì˜¤ë¥˜\"\n",
    "\n",
    "# Function Calling ë„êµ¬ ì •ì˜\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"ë„ì‹œ ì´ë¦„\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate_math\", \n",
    "            \"description\": \"ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\"type\": \"string\", \"description\": \"ê³„ì‚°í•  ìˆ˜ì‹\"}\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=== ReAct with Function Calling ===\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ìš”ì²­\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"ì„œìš¸ ë‚ ì”¨ í™•ì¸í•˜ê³  25 * 30 ê³„ì‚°í•´ì„œ ìš”ì•½í•´ì¤˜\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬\n",
    "if response.choices[0].message.tool_calls:\n",
    "    messages.append(response.choices[0].message)\n",
    "    \n",
    "    for tool_call in response.choices[0].message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            result = get_weather(arguments[\"city\"])\n",
    "        elif function_name == \"calculate_math\":\n",
    "            result = calculate_math(arguments[\"expression\"])\n",
    "        else:\n",
    "            result = \"Unknown function\"\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": function_name,\n",
    "            \"content\": str(result)\n",
    "        })\n",
    "        print(f\"Tool used: {function_name} -> {result}\")\n",
    "    \n",
    "    # ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFinal Answer:\")\n",
    "    print(final_response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"No tool calls made:\")\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Program-Aided Language Model (PAL)\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: ëª¨ë¸ì´ ì½”ë“œ(ì˜ˆ: Python)ë¥¼ ì‘ì„± â†’ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë‹µë³€ì— ì‚¬ìš©\n",
    "\n",
    "- ì¥ì : ìˆ˜ì¹˜/ì¡°í•©/íƒìƒ‰ ì •í™•ë„â†‘, ì¬í˜„ì„±â†‘\n",
    "- ì„¤ê³„ íŒ: ì•ˆì „ ì‹¤í–‰ í™˜ê²½(ìƒŒë“œë°•ìŠ¤), ê¸ˆì§€ ëª¨ë“ˆ ì°¨ë‹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. PAL - ìˆ˜í•™ í•¨ìˆ˜ ìƒì„± ë° ì‹¤í–‰\n",
    "pal_prompt = \"\"\"Write Python function gcd_list(nums: list[int]) -> int using math.gcd and functools.reduce.\n",
    "Return ONLY the code, no explanation.\"\"\"\n",
    "\n",
    "print(\"=== PAL ì½”ë“œ ìƒì„± ===\")\n",
    "print(\"Ollama:\")\n",
    "pal_ollama = run_ollama(\"llama3.1:8b\", pal_prompt)\n",
    "print(pal_ollama)\n",
    "\n",
    "print(\"\\nOpenAI:\")\n",
    "pal_openai = run_openai(pal_prompt, max_completion_tokens=200)\n",
    "print(pal_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAL ì½”ë“œ ì‹¤í–‰ (ì•ˆì „í•œ ë°©ì‹)\n",
    "def safe_execute_code(code: str, test_input: list) -> str:\n",
    "    \"\"\"ì•ˆì „í•˜ê²Œ ì½”ë“œë¥¼ ì‹¤í–‰\"\"\"\n",
    "    try:\n",
    "        # ìœ„í—˜í•œ í‚¤ì›Œë“œ ì²´í¬\n",
    "        dangerous_keywords = ['import os', 'import sys', 'open(', 'exec', 'eval']\n",
    "        for keyword in dangerous_keywords:\n",
    "            if keyword in code:\n",
    "                return f\"ìœ„í—˜í•œ ì½”ë“œ ê°ì§€: {keyword}\"\n",
    "        \n",
    "        # í—ˆìš©ëœ importë§Œ ì¶”ê°€\n",
    "        safe_code = \"import math\\nimport functools\\n\" + code\n",
    "        \n",
    "        # ì½”ë“œ ì‹¤í–‰\n",
    "        local_env = {}\n",
    "        exec(safe_code, {\"math\": math, \"functools\": functools}, local_env)\n",
    "        \n",
    "        # í•¨ìˆ˜ ì‹¤í–‰\n",
    "        if 'gcd_list' in local_env:\n",
    "            result = local_env['gcd_list'](test_input)\n",
    "            return str(result)\n",
    "        else:\n",
    "            return \"í•¨ìˆ˜ gcd_listë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\"\n",
    "    except Exception as e:\n",
    "        return f\"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_numbers = [24, 60, 36]\n",
    "print(f\"=== PAL ì½”ë“œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸: gcd_list({test_numbers}) ===\")\n",
    "\n",
    "# OpenAI ì½”ë“œ ì‹¤í–‰\n",
    "openai_result = safe_execute_code(pal_openai, test_numbers)\n",
    "print(f\"OpenAI ì½”ë“œ ì‹¤í–‰ ê²°ê³¼: {openai_result}\")\n",
    "\n",
    "# ì •ë‹µ í™•ì¸ (ìˆ˜ë™ ê³„ì‚°)\n",
    "actual_gcd = functools.reduce(math.gcd, test_numbers)\n",
    "print(f\"ì‹¤ì œ GCD({test_numbers}): {actual_gcd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PAL ë³µì¡í•œ ê³„ì‚° ===\n",
      "ìƒì„±ëœ ì½”ë“œ:\n",
      "\n",
      "\n",
      "ì‹¤í–‰ ê²°ê³¼: \n",
      "ìˆ˜ë™ ê³„ì‚° ê²€ì¦: 128.0 cmÂ²\n"
     ]
    }
   ],
   "source": [
    "# PAL ë³µì¡í•œ ê³„ì‚° ì˜ˆì‹œ\n",
    "complex_pal_prompt = \"\"\"Write Python code to solve this problem:\n",
    "\"ì‚¬ë‹¤ë¦¬ê¼´ì˜ ë„“ì´ë¥¼ êµ¬í•˜ì‹œì˜¤. ìœ—ë³€ 12cm, ì•„ë«ë³€ 20cm, ë†’ì´ 8cm\"\n",
    "\n",
    "Return executable Python code that calculates and prints the result.\"\"\"\n",
    "\n",
    "print(\"=== PAL ë³µì¡í•œ ê³„ì‚° ===\")\n",
    "complex_code = run_openai(complex_pal_prompt, max_completion_tokens=200)\n",
    "print(\"ìƒì„±ëœ ì½”ë“œ:\")\n",
    "print(complex_code)\n",
    "\n",
    "# ì•ˆì „ ì‹¤í–‰\n",
    "def safe_execute_calculation(code: str) -> str:\n",
    "    try:\n",
    "        # ì¶œë ¥ ìº¡ì²˜ë¥¼ ìœ„í•œ StringIO ì‚¬ìš©\n",
    "        from io import StringIO\n",
    "        import sys\n",
    "        \n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = captured_output = StringIO()\n",
    "        \n",
    "        # ì½”ë“œì—ì„œ ìœ„í—˜ ìš”ì†Œ ì œê±° í›„ ì‹¤í–‰\n",
    "        clean_code = code.replace('```python', '').replace('```', '')\n",
    "        exec(clean_code)\n",
    "        \n",
    "        sys.stdout = old_stdout\n",
    "        return captured_output.getvalue().strip()\n",
    "    except Exception as e:\n",
    "        if 'sys' in locals():\n",
    "            sys.stdout = old_stdout\n",
    "        return f\"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "result = safe_execute_calculation(complex_code)\n",
    "print(f\"\\nì‹¤í–‰ ê²°ê³¼: {result}\")\n",
    "\n",
    "# ìˆ˜ë™ ê²€ì¦\n",
    "area = (12 + 20) * 8 / 2\n",
    "print(f\"ìˆ˜ë™ ê³„ì‚° ê²€ì¦: {area} cmÂ²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê¸°ë²• ë¹„êµ ë° ì„±ëŠ¥ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì¼í•œ ë¬¸ì œì— ëŒ€í•œ ë‹¤ì–‘í•œ ê¸°ë²• ë¹„êµ\n",
    "comparison_problem = \"23 Ã— 47 + 15 Ã— 32ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤\"\n",
    "\n",
    "print(\"=== ê¸°ë²•ë³„ ì„±ëŠ¥ ë¹„êµ: ë³µí•© ê³„ì‚° ë¬¸ì œ ===\")\n",
    "print(f\"ë¬¸ì œ: {comparison_problem}\")\n",
    "print(f\"ì •ë‹µ: {23 * 47 + 15 * 32}\")\n",
    "print()\n",
    "\n",
    "# 1. Zero-shot\n",
    "zero_shot = run_openai(f\"Calculate: {comparison_problem}\", max_completion_tokens=100)\n",
    "print(f\"Zero-shot: {zero_shot}\")\n",
    "\n",
    "# 2. Chain of Thought\n",
    "cot = run_openai(f\"Solve step by step: {comparison_problem}\", max_completion_tokens=200)\n",
    "print(f\"\\nCoT: {cot}\")\n",
    "\n",
    "# 3. PAL\n",
    "pal_calc_prompt = f\"Write Python code to calculate: {comparison_problem}\"\n",
    "pal_code = run_openai(pal_calc_prompt, max_completion_tokens=150)\n",
    "pal_result = safe_execute_calculation(pal_code)\n",
    "print(f\"\\nPAL ì½”ë“œ: {pal_code}\")\n",
    "print(f\"PAL ê²°ê³¼: {pal_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ë¡  í’ˆì§ˆ í‰ê°€ ë©”íŠ¸ë¦­\n",
    "def evaluate_reasoning_quality(response: str, expected_answer: any) -> dict:\n",
    "    \"\"\"ì¶”ë¡  í’ˆì§ˆ í‰ê°€\"\"\"\n",
    "    metrics = {\n",
    "        'has_steps': bool(re.search(r'(step|ë‹¨ê³„|first|then|next)', response, re.I)),\n",
    "        'has_calculation': bool(re.search(r'[0-9]+\\s*[+\\-*/Ã—Ã·]\\s*[0-9]+', response)),\n",
    "        'has_final_answer': bool(re.search(r'(ë‹µ|answer|result|ê²°ê³¼)', response, re.I)),\n",
    "        'length': len(response),\n",
    "        'confidence_words': len(re.findall(r'(í™•ì‹¤|certain|clear|obvious)', response, re.I))\n",
    "    }\n",
    "    \n",
    "    # ìˆ«ì ì •í™•ë„ ì²´í¬ (ê°„ë‹¨í•œ ë²„ì „)\n",
    "    numbers = re.findall(r'\\b\\d+\\b', response)\n",
    "    if numbers:\n",
    "        try:\n",
    "            final_number = int(numbers[-1])  # ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ìµœì¢… ë‹µìœ¼ë¡œ ê°„ì£¼\n",
    "            metrics['correct_answer'] = (final_number == expected_answer)\n",
    "        except:\n",
    "            metrics['correct_answer'] = False\n",
    "    else:\n",
    "        metrics['correct_answer'] = False\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰\n",
    "expected = 23 * 47 + 15 * 32\n",
    "\n",
    "evaluations = {\n",
    "    'Zero-shot': evaluate_reasoning_quality(zero_shot, expected),\n",
    "    'CoT': evaluate_reasoning_quality(cot, expected),\n",
    "    'PAL': evaluate_reasoning_quality(pal_result, expected)\n",
    "}\n",
    "\n",
    "print(\"\\n=== ì¶”ë¡  í’ˆì§ˆ í‰ê°€ ===\")\n",
    "for method, metrics in evaluations.items():\n",
    "    print(f\"\\n{method}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì¢…í•© ì‹¤ìŠµ: í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===\n",
      "\n",
      "--- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1 ---\n",
      "ë¬¸ì œ: 125 Ã— 8 + 75 Ã· 3ì„ ê³„ì‚°í•˜ì‹œì˜¤\n",
      "ë¶„ë¥˜ëœ ë¬¸ì œ ìœ í˜•: math\n",
      "ì‚¬ìš©ëœ ê¸°ë²•: PAL, CoT\n",
      "\n",
      "PAL ê²°ê³¼: \n",
      "\n",
      "CoT ê²°ê³¼: ...\n",
      "\n",
      "--- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2 ---\n",
      "ë¬¸ì œ: ìƒˆë¡œìš´ ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ëŸ°ì¹­ ì „ëµì„ 3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”\n",
      "ë¶„ë¥˜ëœ ë¬¸ì œ ìœ í˜•: planning\n",
      "ì‚¬ìš©ëœ ê¸°ë²•: ToT\n",
      "\n",
      "ToT ê²°ê³¼: ...\n",
      "\n",
      "--- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3 ---\n",
      "ë¬¸ì œ: 'ë°°ì†¡ì´ ë¹¨ë¼ì„œ ë§Œì¡±í•´ìš”'ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”\n",
      "ë¶„ë¥˜ëœ ë¬¸ì œ ìœ í˜•: classification\n",
      "ì‚¬ìš©ëœ ê¸°ë²•: Few-shot\n",
      "\n",
      "Few-shot ê²°ê³¼: ...\n",
      "\n",
      "--- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 4 ---\n",
      "ë¬¸ì œ: ì¸ê³µì§€ëŠ¥ì˜ ì¥ë‹¨ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "ë¶„ë¥˜ëœ ë¬¸ì œ ìœ í˜•: general\n",
      "ì‚¬ìš©ëœ ê¸°ë²•: CoT\n",
      "\n",
      "CoT ê²°ê³¼: ...\n"
     ]
    }
   ],
   "source": [
    "# ì—¬ëŸ¬ ê¸°ë²•ì„ ì¡°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ\n",
    "def hybrid_reasoning_system(problem: str, problem_type: str = \"auto\") -> dict:\n",
    "    \"\"\"ë¬¸ì œ ìœ í˜•ì— ë”°ë¼ ìµœì  ê¸°ë²•ì„ ìë™ ì„ íƒí•˜ëŠ” ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    # ë¬¸ì œ ìœ í˜• ìë™ ë¶„ë¥˜\n",
    "    if problem_type == \"auto\":\n",
    "        if re.search(r'\\d+\\s*[+\\-*/Ã—Ã·]\\s*\\d+', problem):\n",
    "            problem_type = \"math\"\n",
    "        elif re.search(r'(ì „ëµ|ê³„íš|ë°©ë²•|approach|strategy)', problem, re.I):\n",
    "            problem_type = \"planning\"\n",
    "        elif re.search(r'(ë¶„ë¥˜|classify|sentiment)', problem, re.I):\n",
    "            problem_type = \"classification\"\n",
    "        else:\n",
    "            problem_type = \"general\"\n",
    "    \n",
    "    results = {\"problem_type\": problem_type, \"methods_used\": [], \"results\": {}}\n",
    "    \n",
    "    # ë¬¸ì œ ìœ í˜•ë³„ ìµœì  ê¸°ë²• ì ìš©\n",
    "    if problem_type == \"math\":\n",
    "        # ìˆ˜í•™ ë¬¸ì œ: PAL + CoT ì¡°í•©\n",
    "        results[\"methods_used\"] = [\"PAL\", \"CoT\"]\n",
    "        \n",
    "        # PAL ì‹œë„\n",
    "        pal_prompt = f\"Write Python code to solve: {problem}\"\n",
    "        pal_code = run_openai(pal_prompt, max_completion_tokens=200)\n",
    "        pal_result = safe_execute_calculation(pal_code)\n",
    "        results[\"results\"][\"PAL\"] = {\"code\": pal_code, \"result\": pal_result}\n",
    "        \n",
    "        # CoT ë°±ì—…\n",
    "        cot_prompt = f\"Solve step by step with detailed reasoning: {problem}\"\n",
    "        cot_result = run_openai(cot_prompt, max_completion_tokens=300)\n",
    "        results[\"results\"][\"CoT\"] = cot_result\n",
    "        \n",
    "    elif problem_type == \"planning\":\n",
    "        # ê¸°íš ë¬¸ì œ: ToT\n",
    "        results[\"methods_used\"] = [\"ToT\"]\n",
    "        tot_prompt = f\"\"\"Generate 3 different approaches to: {problem}\n",
    "For each: outline, pros/cons, feasibility rating.\n",
    "Choose the best approach.\"\"\"\n",
    "        tot_result = run_openai(tot_prompt, max_completion_tokens=500)\n",
    "        results[\"results\"][\"ToT\"] = tot_result\n",
    "        \n",
    "    elif problem_type == \"classification\":\n",
    "        # ë¶„ë¥˜ ë¬¸ì œ: Few-shot\n",
    "        results[\"methods_used\"] = [\"Few-shot\"]\n",
    "        few_shot_prompt = f\"\"\"Examples of classification:\n",
    "Input: \"ì¢‹ì€ ì œí’ˆì´ì—ìš”\" -> positive\n",
    "Input: \"ë³„ë¡œì˜ˆìš”\" -> negative  \n",
    "Input: \"ë³´í†µì…ë‹ˆë‹¤\" -> neutral\n",
    "\n",
    "Now classify: {problem}\"\"\"\n",
    "        few_shot_result = run_openai(few_shot_prompt, max_completion_tokens=100)\n",
    "        results[\"results\"][\"Few-shot\"] = few_shot_result\n",
    "        \n",
    "    else:\n",
    "        # ì¼ë°˜ ë¬¸ì œ: CoT\n",
    "        results[\"methods_used\"] = [\"CoT\"]\n",
    "        cot_prompt = f\"Think step by step and solve: {problem}\"\n",
    "        cot_result = run_openai(cot_prompt,max_completion_tokens=300)\n",
    "        results[\"results\"][\"CoT\"] = cot_result\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤\n",
    "test_cases = [\n",
    "    \"125 Ã— 8 + 75 Ã· 3ì„ ê³„ì‚°í•˜ì‹œì˜¤\",\n",
    "    \"ìƒˆë¡œìš´ ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ëŸ°ì¹­ ì „ëµì„ 3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”\", \n",
    "    \"'ë°°ì†¡ì´ ë¹¨ë¼ì„œ ë§Œì¡±í•´ìš”'ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”\",\n",
    "    \"ì¸ê³µì§€ëŠ¥ì˜ ì¥ë‹¨ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "]\n",
    "\n",
    "print(\"=== í•˜ì´ë¸Œë¦¬ë“œ ì¶”ë¡  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n--- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i} ---\")\n",
    "    print(f\"ë¬¸ì œ: {test_case}\")\n",
    "    \n",
    "    result = hybrid_reasoning_system(test_case)\n",
    "    \n",
    "    print(f\"ë¶„ë¥˜ëœ ë¬¸ì œ ìœ í˜•: {result['problem_type']}\")\n",
    "    print(f\"ì‚¬ìš©ëœ ê¸°ë²•: {', '.join(result['methods_used'])}\")\n",
    "    \n",
    "    for method, output in result['results'].items():\n",
    "        if isinstance(output, dict):\n",
    "            print(f\"\\n{method} ê²°ê³¼: {output.get('result', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"\\n{method} ê²°ê³¼: {output[:200]}...\")  # ì²˜ìŒ 200ìë§Œ í‘œì‹œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì •ë¦¬ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤\n",
    "\n",
    "### ê¸°ë²•ë³„ ì ìš© ê°€ì´ë“œ\n",
    "\n",
    "| ê¸°ë²• | ì ìš© ìƒí™© | ì¥ì  | ë‹¨ì  |\n",
    "|------|-----------|------|------|\n",
    "| Zero-shot | ê°„ë‹¨í•œ ë¶„ë¥˜, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ | ë¹ ë¦„, ê°„ë‹¨ | ë¶ˆì•ˆì •í•œ í¬ë§· |\n",
    "| Few-shot | í¬ë§· ì•ˆì •í™” í•„ìš”ì‹œ | ì¼ê´€ëœ ì¶œë ¥ | ì»¨í…ìŠ¤íŠ¸ ì†Œëª¨ |\n",
    "| CoT | ë…¼ë¦¬ì  ì¶”ë¡ , ìˆ˜í•™ ë¬¸ì œ | ë†’ì€ ì •í™•ë„ | ê¸´ ì‘ë‹µ ì‹œê°„ |\n",
    "| Least-to-Most | ë³µì¡í•œ ì œì•½ ë¬¸ì œ | ì²´ê³„ì  ì ‘ê·¼ | ë³µì¡í•œ ì„¤ê³„ |\n",
    "| ToT | ì°½ì˜ì  ë¬¸ì œ, ì „ëµ ìˆ˜ë¦½ | ë‹¤ì–‘í•œ ê´€ì  | ë†’ì€ ë¹„ìš© |\n",
    "| ReAct | ì‹¤ì‹œê°„ ë°ì´í„° í•„ìš” | ìµœì‹  ì •ë³´ | ë„êµ¬ ì˜ì¡´ì„± |\n",
    "| PAL | ì •í™•í•œ ê³„ì‚° | 100% ì •í™• | ì½”ë“œ ì•ˆì „ì„± |\n",
    "\n",
    "### ì‹¤ë¬´ ê¶Œì¥ì‚¬í•­\n",
    "\n",
    "1. **ë¬¸ì œ ìœ í˜• ìë™ ë¶„ë¥˜** ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "2. **í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•**ìœ¼ë¡œ ì—¬ëŸ¬ ê¸°ë²• ì¡°í•©\n",
    "3. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**ì„ í†µí•œ ì§€ì†ì  ê°œì„ \n",
    "4. **ì•ˆì „ì„± ê²€ì¦** (íŠ¹íˆ PAL ì‚¬ìš©ì‹œ)\n",
    "5. **ë¹„ìš© íš¨ìœ¨ì„±** ê³ ë ¤í•œ ê¸°ë²• ì„ íƒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ajou-llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
