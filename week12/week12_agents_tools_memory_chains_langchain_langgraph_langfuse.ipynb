{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 12 – Agents, Tools, Memory, Chains (LangChain + LangGraph)\n",
        "\n",
        "이 노트북은 다음 세 가지 축으로 구성된 예제 코드를 포함합니다.\n",
        "\n",
        "1. **LangChain**: 기본 Chat, Chain, Memory, Tool, Agent (`create_agent`)\n",
        "2. **LangGraph**: StateGraph 기반 간단한 Agent 그래프\n",
        "\n",
        "> ⚠️ 주의: 실제 실행을 위해서는 `OPENAI_API_KEY`, `Langsmith` 관련 환경변수 설정이 필요합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 설정 & 패키지 설치\n",
        "\n",
        "실습 환경에 맞게 한 번만 설치하면 됩니다. (Colab, 로컬 venv 등)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "579a9c48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langsmith in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (0.4.29)\n",
            "Requirement already satisfied: langchain in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (1.0.7)\n",
            "Requirement already satisfied: langchain_openai in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (1.0.3)\n",
            "Requirement already satisfied: langgraph in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-core in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (1.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langsmith) (3.11.3)\n",
            "Requirement already satisfied: packaging>=23.2 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langsmith) (2.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: anyio in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langgraph) (1.0.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langchain_openai) (2.8.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.9.18)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sjcha/Documents/3. 아주대AI대학원/2025-2nd-semester/ajou-llmops-2025-2nd-semester/ajou-llmops/lib/python3.11/site-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langsmith langchain langchain_openai langgraph langchain-core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 공통 설정: 환경변수 & 모델 헬퍼\n",
        "\n",
        "- `.env` 파일에서 OpenAI / LangFuse 키를 로딩\n",
        "- 공통 Chat 모델 생성 헬퍼 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LANGSMITH_TRACING: true\n",
            "LANGSMITH_PROJECT: ajou-ai-practical-project10-llmops\n",
            "LANGSMITH_API_KEY set?: True\n",
            "OPENAI_API_KEY set?: True\n"
          ]
        }
      ],
      "source": [
        "# 설치 (환경마다 한 번만)\n",
        "# %pip install -q langsmith langchain_core langchain_openai langgraph\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # .env 로딩\n",
        "\n",
        "# LangSmith 기본 체크\n",
        "print(\"LANGSMITH_TRACING:\", os.getenv(\"LANGSMITH_TRACING\"))\n",
        "print(\"LANGSMITH_PROJECT:\", os.getenv(\"LANGSMITH_PROJECT\"))\n",
        "print(\"LANGSMITH_API_KEY set?:\", bool(os.getenv(\"LANGSMITH_API_KEY\")))\n",
        "\n",
        "# OpenAI 키 체크\n",
        "print(\"OPENAI_API_KEY set?:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"⚠️ WARNING: OPENAI_API_KEY가 설정되지 않았습니다. 실제 실행 전 반드시 설정하세요.\")\n",
        "\n",
        "# LangChain / LangGraph 공통에서 사용할 기본 모델 헬퍼\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def get_chat_model(\n",
        "    model_name: str = \"gpt-4o-mini\",\n",
        "    temperature: float = 0.1,\n",
        "):\n",
        "    '''\n",
        "    공통 Chat 모델 생성 헬퍼.\n",
        "    - 필요에 따라 로컬 LLM (ex. ollama) 으로 교체 가능.\n",
        "    '''\n",
        "    return ChatOpenAI(\n",
        "        model=model_name,\n",
        "        temperature=temperature,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. LangChain 기본 Chat & Chain\n",
        "\n",
        "가장 기본적인 **프롬프트 → LLM** 체인을 정의하고 실행해 봅니다.\n",
        "- `ChatPromptTemplate` + `ChatOpenAI` + `|` 연산자로 구성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain agents are components designed to enable language models to interact with external tools and data sources, allowing them to perform complex tasks beyond simple text generation. They utilize a combination of a language model, a decision-making mechanism, and various tools or APIs to execute actions based on user input or specific prompts. This architecture empowers developers to create applications that can reason, retrieve information, and automate workflows by leveraging the capabilities of language models in a structured manner.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# 3-1. 간단한 프롬프트 템플릿\n",
        "basic_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant for LLMOps students.\"),\n",
        "        (\"human\", \"Explain the concept of {topic} in 3 sentences.\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 3-2. 체인 구성 (Prompt -> Model)\n",
        "basic_chain = basic_prompt | get_chat_model()\n",
        "\n",
        "# 3-3. 테스트 실행\n",
        "if OPENAI_API_KEY:\n",
        "    result = basic_chain.invoke({\"topic\": \"LangChain agents\"})\n",
        "    print(result.content)\n",
        "else:\n",
        "    print(\"OPENAI_API_KEY 미설정: 체인 예시는 구조만 확인하세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. LangChain Memory – `RunnableWithMessageHistory`\n",
        "\n",
        "대화형 에이전트에서 **대화 Memory** 를 관리하기 위해 `RunnableWithMessageHistory` 를 사용합니다.\n",
        "\n",
        "- 세션 ID 별로 메시지 히스토리를 저장\n",
        "- LangChain의 `messages` 입력/출력을 자동으로 관리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Session A: 첫 질문 ===\n",
            "Hi, Sungjae! I’ll remember your name. How can I assist you today?\n",
            "\n",
            "=== Session A: 후속 질문 ===\n",
            "I'm sorry, but I don't have access to your name or any personal information. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, List\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.runnables import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
        "\n",
        "# 세션별 메모리를 관리하는 간단한 in-memory store\n",
        "_chat_store: Dict[str, InMemoryChatMessageHistory] = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in _chat_store:\n",
        "        _chat_store[session_id] = InMemoryChatMessageHistory()\n",
        "    return _chat_store[session_id]\n",
        "\n",
        "# 메모리 포함 Chat 체인 정의\n",
        "memory_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that remembers the conversation.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory_chain = memory_prompt | get_chat_model()\n",
        "\n",
        "conversation = RunnableWithMessageHistory(\n",
        "    memory_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",   # 입력에서 대화 텍스트가 있는 key\n",
        "    history_messages_key=\"history\",  # 히스토리 저장 key\n",
        ")\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "    print(\"=== Session A: 첫 질문 ===\")\n",
        "    res1 = conversation.invoke(\n",
        "        {\"input\": \"Hi, I am Sungjae. Please remember my name.\"},\n",
        "        config={\"configurable\": {\"session_id\": \"session-a\"}},\n",
        "    )\n",
        "    print(res1.content)\n",
        "\n",
        "    print(\"\\n=== Session A: 후속 질문 ===\")\n",
        "    res2 = conversation.invoke(\n",
        "        {\"input\": \"What is my name?\"},\n",
        "        config={\"configurable\": {\"session_id\": \"session-a\"}},\n",
        "    )\n",
        "    print(res2.content)\n",
        "else:\n",
        "    print(\"OPENAI_API_KEY 미설정: Memory 체인 구조만 확인하세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. LangChain Tools – `@tool` & `ToolRuntime`\n",
        "\n",
        "에이전트가 호출할 수 있는 **Tool** 을 정의합니다.\n",
        "\n",
        "- 간단한 `calculator` / `get_server_time`\n",
        "- `ToolRuntime` 을 활용해 현재 대화 상태에 접근하는 `summarize_conversation`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[StructuredTool(name='calculator', description='주어진 수식(expression)을 Python eval 로 계산합니다 (간단 예제).', args_schema=<class 'langchain_core.utils.pydantic.calculator'>, func=<function calculator at 0x107ae7740>),\n",
              " StructuredTool(name='get_server_time', description='서버 현재 시간을 ISO 포맷으로 반환합니다.', args_schema=<class 'langchain_core.utils.pydantic.get_server_time'>, func=<function get_server_time at 0x1337d3f60>),\n",
              " StructuredTool(name='echo_upper', description='텍스트를 대문자로 변환하여 반환합니다.', args_schema=<class 'langchain_core.utils.pydantic.echo_upper'>, func=<function echo_upper at 0x1337d2520>),\n",
              " StructuredTool(name='summarize_conversation', description='지금까지의 대화를 짧게 요약합니다.', args_schema=<class 'langchain_core.utils.pydantic.summarize_conversation'>, func=<function summarize_conversation at 0x1337f4cc0>)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from langchain.tools import tool, ToolRuntime\n",
        "\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    '''주어진 수식(expression)을 Python eval 로 계산합니다 (간단 예제).'''\n",
        "    try:\n",
        "        # ⚠️ 실제 서비스에서는 eval 대신 안전한 파서 사용 필요\n",
        "        result = eval(expression, {\"__builtins__\": {}})\n",
        "        return f\"{expression} = {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Failed to evaluate expression: {e}\"\n",
        "\n",
        "@tool\n",
        "def get_server_time() -> str:\n",
        "    '''서버 현재 시간을 ISO 포맷으로 반환합니다.'''\n",
        "    return datetime.now().isoformat()\n",
        "\n",
        "@tool\n",
        "def echo_upper(text: str) -> str:\n",
        "    '''텍스트를 대문자로 변환하여 반환합니다.'''\n",
        "    return text.upper()\n",
        "\n",
        "# ToolRuntime 활용 예시\n",
        "@tool\n",
        "def summarize_conversation(runtime: ToolRuntime) -> str:\n",
        "    '''지금까지의 대화를 짧게 요약합니다.'''\n",
        "    messages = runtime.state.get(\"messages\", [])\n",
        "    # messages 는 BaseMessage 리스트\n",
        "    user_turns = [m.content for m in messages if m.type == \"human\"]\n",
        "    ai_turns = [m.content for m in messages if m.type == \"ai\"]\n",
        "    return (\n",
        "        f\"User said {len(user_turns)} things, \"\n",
        "        f\"Assistant replied {len(ai_turns)} times. \"\n",
        "        \"대화 내용은 에이전트가 직접 요약해서 사용자에게 전달하세요.\"\n",
        "    )\n",
        "\n",
        "tools = [calculator, get_server_time, echo_upper, summarize_conversation]\n",
        "tools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. LangChain Agent – `create_agent`\n",
        "\n",
        "새로운 `create_agent` API 를 활용해 **ReAct 패턴 기반 에이전트**를 구성합니다.\n",
        "\n",
        "- LLM + Tools 조합\n",
        "- `messages` 기반 입력\n",
        "- `.invoke()` / `.stream()` 으로 실행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "현재 시간은 2025년 11월 17일 22시 39분입니다.  \n",
            "또한, \\( 2 \\times (3 + 5) \\)의 결과는 16입니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "agent_model = get_chat_model(model_name=\"gpt-4o-mini\", temperature=0.2)\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an LLMOps teaching assistant.\\n\"\n",
        "    \"You can use tools to calculate expressions, get server time, \"\n",
        "    \"and transform text to UPPERCASE.\\n\"\n",
        "    \"When appropriate, think step by step and show intermediate reasoning briefly.\"\n",
        ")\n",
        "\n",
        "agent = create_agent(\n",
        "    model=agent_model,\n",
        "    tools=tools,\n",
        "    system_prompt=system_prompt,\n",
        ")\n",
        "\n",
        "def run_simple_agent(query: str):\n",
        "    if not OPENAI_API_KEY:\n",
        "        print(\"OPENAI_API_KEY 미설정: 에이전트 구조만 확인하세요.\")\n",
        "        return\n",
        "\n",
        "    events = agent.stream(\n",
        "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "    final = None\n",
        "    for event in events:\n",
        "        final = event\n",
        "    if final:\n",
        "        # 마지막 메시지 출력\n",
        "        print(final[\"messages\"][-1].content)\n",
        "\n",
        "# 간단 테스트\n",
        "run_simple_agent(\"지금 시간이 몇 시인지 알려주고, 2 * (3 + 5)의 결과도 계산해줘.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. LangChain Agent + Memory 결합\n",
        "\n",
        "앞에서 정의한 `agent` 를 다시 감싸서 **세션 기반 Memory** 를 추가합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Session AGENT-1: 첫 질문 ===\n",
            "알겠습니다, 성재님! 당신의 이름을 기억하겠습니다.\n",
            "\n",
            "=== Session AGENT-1: 후속 질문 ===\n",
            "아직 당신의 이름을 말씀해 주신 적이 없습니다. 이름을 알려주시면 기억하겠습니다!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "# agent 는 이미 LangGraph 기반 Runnable (messages -> messages)\n",
        "# 이를 RunnableWithMessageHistory 로 감싸서 대화 히스토리 유지\n",
        "agent_with_memory = RunnableWithMessageHistory(\n",
        "    agent,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",  # create_agent 는 messages 기반 입력\n",
        "    history_messages_key=\"history\",\n",
        ")\n",
        "\n",
        "def chat_with_agent(session_id: str, user_message: str):\n",
        "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
        "    result = agent_with_memory.invoke(\n",
        "        {\"messages\": messages},\n",
        "        config={\"configurable\": {\"session_id\": session_id}},\n",
        "    )\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "    print(\"=== Session AGENT-1: 첫 질문 ===\")\n",
        "    print(chat_with_agent(\"agent-session-1\", \"내 이름을 성재라고 기억해줘.\"))\n",
        "\n",
        "    print(\"\\n=== Session AGENT-1: 후속 질문 ===\")\n",
        "    print(chat_with_agent(\"agent-session-1\", \"내 이름이 뭐라고 했지?\"))\n",
        "else:\n",
        "    print(\"OPENAI_API_KEY 미설정: Agent + Memory 예시는 구조만 확인하세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. LangGraph – 기본 StateGraph 예제\n",
        "\n",
        "LangGraph 를 사용해 **명시적인 StateGraph** 를 구성합니다.\n",
        "\n",
        "- `State` (TypedDict) 정의\n",
        "- `messages` 필드를 `add_messages` 리듀서로 관리\n",
        "- `run_llm` 노드를 거치는 단순한 그래프\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangGraph is a framework designed to facilitate the development and deployment of language models by providing a structured way to represent and manipulate language data. It enables users to create complex language processing workflows by integrating various components and tools, enhancing the efficiency and effectiveness of natural language understanding tasks.\n"
          ]
        }
      ],
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class ChatState(TypedDict):\n",
        "    messages: Annotated[list[BaseMessage], add_messages]\n",
        "\n",
        "# 노드 함수: 마지막 메시지를 보고 모델 호출\n",
        "def run_llm_node(state: ChatState) -> ChatState:\n",
        "    model = get_chat_model()\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# 그래프 구성\n",
        "graph_builder = StateGraph(ChatState)\n",
        "graph_builder.add_node(\"llm\", run_llm_node)\n",
        "graph_builder.add_edge(\"llm\", END)\n",
        "graph_builder.set_entry_point(\"llm\")\n",
        "\n",
        "chat_graph = graph_builder.compile()\n",
        "\n",
        "# 실행 예시\n",
        "if OPENAI_API_KEY:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "\n",
        "    events = chat_graph.stream(\n",
        "        {\"messages\": [HumanMessage(content=\"Explain what LangGraph is in 2 sentences.\")]}, \n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "    final_state = None\n",
        "    for s in events:\n",
        "        final_state = s\n",
        "    print(final_state[\"messages\"][-1].content)\n",
        "else:\n",
        "    print(\"OPENAI_API_KEY 미설정: LangGraph 예시는 구조만 확인하세요.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. LangGraph + Tools – Tool 호출 노드\n",
        "\n",
        "LangGraph 내에서 **Tool 을 직접 호출하는 노드**를 만들어,\n",
        "- 사용자의 요청을 분석해서 Tool 실행\n",
        "- 결과를 메시지에 추가\n",
        "\n",
        "하는 패턴을 보여줍니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CALC 예시 ===\n",
            "[CALC RESULT] 2 * (3 + 5) = 16\n",
            "\n",
            "=== TIME 예시 ===\n",
            "[TIME RESULT] 2025-11-17T22:39:13.112186\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import Tool\n",
        "\n",
        "# 기존 LangChain @tool 로 만든 것들을 LangGraph 노드에서 직접 사용할 수 있음\n",
        "simple_tool_map = {t.name: t for t in tools}\n",
        "\n",
        "def tool_router_node(state: ChatState) -> ChatState:\n",
        "    '''\n",
        "    아주 단순한 규칙 기반 라우터 예시:\n",
        "    - \"CALC:\" 로 시작하면 calculator 사용\n",
        "    - \"TIME\" 을 포함하면 get_server_time 사용\n",
        "    - 그 외에는 echo_upper 사용\n",
        "    '''\n",
        "    from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if not isinstance(last_message, HumanMessage):\n",
        "        return {\"messages\": []}\n",
        "\n",
        "    text = last_message.content.strip()\n",
        "    if text.upper().startswith(\"CALC:\"):\n",
        "        expr = text.split(\"CALC:\", 1)[1].strip()\n",
        "        tool_res = simple_tool_map[\"calculator\"].invoke({\"expression\": expr})\n",
        "        reply = f\"[CALC RESULT] {tool_res}\"\n",
        "    elif \"TIME\" in text.upper():\n",
        "        tool_res = simple_tool_map[\"get_server_time\"].invoke({})\n",
        "        reply = f\"[TIME RESULT] {tool_res}\"\n",
        "    else:\n",
        "        tool_res = simple_tool_map[\"echo_upper\"].invoke({\"text\": text})\n",
        "        reply = f\"[ECHO RESULT] {tool_res}\"\n",
        "\n",
        "    return {\"messages\": [AIMessage(content=reply)]}\n",
        "\n",
        "# 새로운 그래프: tool_router_node 사용\n",
        "graph_builder2 = StateGraph(ChatState)\n",
        "graph_builder2.add_node(\"tool_router\", tool_router_node)\n",
        "graph_builder2.add_edge(\"tool_router\", END)\n",
        "graph_builder2.set_entry_point(\"tool_router\")\n",
        "\n",
        "tool_graph = graph_builder2.compile()\n",
        "\n",
        "# 실행 예시\n",
        "if OPENAI_API_KEY:\n",
        "    from langchain_core.messages import HumanMessage\n",
        "\n",
        "    print(\"=== CALC 예시 ===\")\n",
        "    for s in tool_graph.stream(\n",
        "        {\"messages\": [HumanMessage(content=\"CALC: 2 * (3 + 5)\")]},\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "        pass\n",
        "    print(s[\"messages\"][-1].content)\n",
        "\n",
        "    print(\"\\n=== TIME 예시 ===\")\n",
        "    for s in tool_graph.stream(\n",
        "        {\"messages\": [HumanMessage(content=\"What TIME is it?\")]},\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "        pass\n",
        "    print(s[\"messages\"][-1].content)\n",
        "else:\n",
        "    print(\"OPENAI_API_KEY 미설정: Tool Router 그래프 구조만 확인하세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdf6b6e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. 정리\n",
        "\n",
        "이 노트북에서 다룬 내용 요약:\n",
        "\n",
        "1. **LangChain**\n",
        "   - 기본 Chat Chain (`ChatPromptTemplate` + `ChatOpenAI`)\n",
        "   - `RunnableWithMessageHistory` 기반 Memory\n",
        "   - `@tool`, `ToolRuntime` 기반 Tool 정의\n",
        "   - `create_agent` 로 Agent 구축 + Memory 결합\n",
        "\n",
        "2. **LangGraph**\n",
        "   - `StateGraph`, `add_messages` 기반 ChatState 정의\n",
        "   - LLM 노드 / Tool Router 노드 예제\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3e7413",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "created": "2025-11-17T07:38:05.720188Z",
    "kernelspec": {
      "display_name": "ajou-llmops",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
