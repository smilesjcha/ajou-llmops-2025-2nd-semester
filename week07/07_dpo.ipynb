{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2a08f9",
   "metadata": {},
   "source": [
    "\n",
    "# Week07 — DPO(Direct Preference Optimization) 실습 (Local 환경용)\n",
    "\n",
    "**목표**\n",
    "- 6주차 SFT(LoRA) 모델을 **초기 정책**으로 활용(있으면)해서, 소형 preference 데이터로 **DPO 학습**을 수행\n",
    "- **Base/SFT vs DPO** 응답을 동일 프롬프트로 비교·기록\n",
    "- (선택) 로컬 **Ollama `llama3.1:8b-instruct`**와 간단 비교\n",
    "\n",
    "> ⚙️ 본 노트북은 **로컬 실행**을 전제로 합니다. GPU가 있으면 4bit/8bit 로딩을 활용하고, CPU만 있어도 작은 모델로 데모가 가능합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ad458",
   "metadata": {},
   "source": [
    "## 0) 환경 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q -U transformers datasets peft accelerate bitsandbytes trl sentencepiece #   langfuse python-dotenv pandas requests torch --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "# ↑ 필요시 주석 해제. CUDA 버전에 맞춰 torch 인덱스는 조정하세요.\n",
    "\n",
    "import sys, platform, torch, os, json, time, random\n",
    "from pathlib import Path\n",
    "print('Python:', sys.version)\n",
    "print('Platform:', platform.platform())\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "print('Torch:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6face",
   "metadata": {},
   "source": [
    "## 1) .env 로드 (OpenAI/Langfuse/Pinecone 키 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = find_dotenv(usecwd=True)\n",
    "if not env_path:\n",
    "    cur = Path.cwd()\n",
    "    for p in [cur] + list(cur.parents):\n",
    "        cand = p / '.env'\n",
    "        if cand.exists():\n",
    "            env_path = str(cand)\n",
    "            break\n",
    "\n",
    "if env_path:\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(\"⚠️ .env를 찾지 못했습니다. 프로젝트 루트에 .env를 생성/배치하세요.\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv('LANGFUSE_PUBLIC_KEY', '')\n",
    "LANGFUSE_SECRET_KEY = os.getenv('LANGFUSE_SECRET_KEY', '')\n",
    "LANGFUSE_HOST = os.getenv('LANGFUSE_HOST', 'https://cloud.langfuse.com')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY', '')\n",
    "\n",
    "print('OpenAI key set:', bool(OPENAI_API_KEY))\n",
    "print('Langfuse host:', LANGFUSE_HOST)\n",
    "print('Pinecone key set:', bool(PINECONE_API_KEY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b4e76",
   "metadata": {},
   "source": [
    "## 2) 실험 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72050c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    # 경로\n",
    "    data_dir: Path = Path('week07/data')\n",
    "    out_dir: Path = Path('week07/runs/dpo')\n",
    "    # 6주차 SFT(LoRA) 어댑터 경로(있으면 사용)\n",
    "    sft_adapter_dir: Path = Path('week06/runs/lora_sft/adapter')\n",
    "    base_model: str = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # 데모용 소형 모델\n",
    "    use_qlora: bool = True  # GPU면 4bit 우선\n",
    "    use_ref_model: bool = False  # 기본은 ref-free DPO\n",
    "    ref_is_base: bool = True     # True면 ref=base, False면 ref=SFT(있으면)\n",
    "    # 토큰/길이\n",
    "    max_length: int = 256\n",
    "    # DPO 하이퍼파라미터\n",
    "    beta: float = 0.1\n",
    "    # 학습 하이퍼파라미터\n",
    "    lr: float = 5e-6\n",
    "    num_epochs: int = 1\n",
    "    per_device_train_batch_size: int = 1\n",
    "    grad_accum_steps: int = 8\n",
    "    logging_steps: int = 10\n",
    "    save_steps: int = 50\n",
    "    warmup_ratio: float = 0.05\n",
    "    # 평가 프롬프트 (전후 비교용)\n",
    "    eval_prompts: list = None\n",
    "\n",
    "cfg = CFG()\n",
    "cfg.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "cfg.out_dir.mkdir(parents=True, exist_ok=True)\n",
    "if cfg.eval_prompts is None:\n",
    "    cfg.eval_prompts = [\n",
    "        (\"안전한 응답\", \"사용자가 위험한 행동을 묻는 경우 어떻게 안내해야 하나요? 세 줄로.\"),\n",
    "        (\"간결한 요약\", \"DPO와 RLHF 차이를 두 줄로 요약해 주세요.\"),\n",
    "        (\"정책 준수\", \"개인정보(전화번호/주민번호 등)를 요구하는 요청에 대한 답변 지침은?\"),\n",
    "        (\"스타일/톤\", \"친절하고 단호한 톤으로 반려를 표현하는 예시를 한 문장으로.\")\n",
    "    ]\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c238c",
   "metadata": {},
   "source": [
    "## 3) Preference 데이터 준비 (없으면 미니 예제 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, random\n",
    "from pathlib import Path\n",
    "\n",
    "prefs_path = cfg.data_dir / 'prefs.jsonl'\n",
    "\n",
    "def write_demo_prefs(path: Path, n=80):\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        prompt = \"안전하고 간결한 답변을 작성하세요. 주제: 대화 정책 정리 #\" + str(i)\n",
    "        chosen = \"정책을 준수하며 간결히 안내합니다. 민감 정보는 수집하거나 저장하지 않습니다.\"\n",
    "        rejected = \"아무렇게나 길게 설명하고, 민감 정보도 요구합니다. 정책은 중요하지 않습니다.\"\n",
    "        rows.append({\"prompt\": prompt, \"chosen\": chosen, \"rejected\": rejected})\n",
    "    with path.open('w', encoding='utf-8') as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "if not prefs_path.exists():\n",
    "    write_demo_prefs(prefs_path, n=120)\n",
    "\n",
    "def read_jsonl(p: Path):\n",
    "    rows = []\n",
    "    with p.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "rows = read_jsonl(prefs_path)\n",
    "print('prefs lines:', len(rows))\n",
    "bad = [r for r in rows if not all(k in r for k in ('prompt','chosen','rejected'))]\n",
    "print('schema invalid:', len(bad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0367351",
   "metadata": {},
   "source": [
    "## 4) Dataset/Tokenizer 로드 & 템플릿 일치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ae461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "ds = Dataset.from_list(rows)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.base_model, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "INSTR_TMPL = \"### Instruction\\n{instruction}\\n\\n### Input\\n{input}\\n\\n### Response\\n\"\n",
    "\n",
    "def build_prompt(instruction:str, _input:str):\n",
    "    return INSTR_TMPL.format(instruction=instruction.strip(), input=_input.strip())\n",
    "\n",
    "print(\"Tokenizer pad token:\", tokenizer.pad_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06721bf4",
   "metadata": {},
   "source": [
    "## 5) 모델 로드 — Base 및 (있으면) SFT 어댑터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc257ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel, prepare_model_for_kbit_training\n",
    "import torch\n",
    "\n",
    "device_map = 'auto'\n",
    "load_in_8bit = False\n",
    "bnb_config = None\n",
    "\n",
    "if torch.cuda.is_available() and cfg.use_qlora:\n",
    "    try:\n",
    "        from bitsandbytes.config import BitsAndBytesConfig\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "        )\n",
    "        print(\"Using 4bit quantization.\")\n",
    "    except Exception as e:\n",
    "        print(\"4bit 불가 → 8bit로 시도:\", e)\n",
    "        load_in_8bit = True\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.base_model,\n",
    "    device_map=device_map,\n",
    "    load_in_8bit=load_in_8bit,\n",
    "    quantization_config=bnb_config if bnb_config else None,\n",
    ")\n",
    "\n",
    "# SFT adapter 적용 가능 여부 확인\n",
    "if cfg.sft_adapter_dir.exists():\n",
    "    print(\"Applying SFT LoRA adapter from:\", cfg.sft_adapter_dir)\n",
    "    sft_policy = PeftModel.from_pretrained(base_model, cfg.sft_adapter_dir)\n",
    "else:\n",
    "    print(\"SFT 어댑터 경로가 없어 Base 모델을 초기 정책으로 사용합니다.\")\n",
    "    sft_policy = base_model\n",
    "\n",
    "# baseline 비교용 모델(학습 전 정책)\n",
    "baseline_model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.base_model,\n",
    "    device_map=device_map,\n",
    "    load_in_8bit=load_in_8bit,\n",
    "    quantization_config=bnb_config if bnb_config else None,\n",
    ")\n",
    "if cfg.sft_adapter_dir.exists():\n",
    "    baseline_model = PeftModel.from_pretrained(baseline_model, cfg.sft_adapter_dir)\n",
    "\n",
    "print(\"모델 준비 완료.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e4fb8",
   "metadata": {},
   "source": [
    "## 6) DPO 학습(DPOTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ff575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from trl import DPOTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(cfg.out_dir),\n",
    "    per_device_train_batch_size=cfg.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=cfg.grad_accum_steps,\n",
    "    learning_rate=cfg.lr,\n",
    "    num_train_epochs=cfg.num_epochs,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    bf16=torch.cuda.is_available(),\n",
    "    logging_steps=cfg.logging_steps,\n",
    "    save_steps=cfg.save_steps,\n",
    "    warmup_ratio=cfg.warmup_ratio,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "ref_model = None\n",
    "if cfg.use_ref_model:\n",
    "    # ref-free가 기본. 필요시 아래 분기 사용\n",
    "    ref_model = AutoModelForCausalLM.from_pretrained(\n",
    "        cfg.base_model,\n",
    "        device_map='auto',\n",
    "        load_in_8bit=load_in_8bit,\n",
    "        quantization_config=bnb_config if bnb_config else None,\n",
    "    )\n",
    "    if not cfg.ref_is_base and cfg.sft_adapter_dir.exists():\n",
    "        ref_model = PeftModel.from_pretrained(ref_model, cfg.sft_adapter_dir)\n",
    "    print(\"참조정책(ref) 사용:\", \"base\" if cfg.ref_is_base else \"sft\")\n",
    "else:\n",
    "    print(\"ref-free DPO 모드\")\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=sft_policy,\n",
    "    ref_model=ref_model,\n",
    "    args=training_args,\n",
    "    beta=cfg.beta,\n",
    "    train_dataset=ds,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=cfg.max_length,\n",
    ")\n",
    "\n",
    "train_result = dpo_trainer.train()\n",
    "save_dir = cfg.out_dir / \"dpo_ckpt\"\n",
    "dpo_trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(\"DPO training done. Saved to\", save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e953738",
   "metadata": {},
   "source": [
    "## 7) 추론 비교: Baseline(초기 정책) vs DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf51f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "def generate(m, tok, instruction, content, max_new_tokens=200):\n",
    "    prompt = build_prompt(instruction, content)\n",
    "    ids = tok(prompt, return_tensors='pt').to(next(m.parameters()).device)\n",
    "    with torch.no_grad():\n",
    "        out = m.generate(**ids, max_new_tokens=max_new_tokens, do_sample=False, temperature=0.0)\n",
    "    text = tok.decode(out[0], skip_special_tokens=True)\n",
    "    return text.split(\"### Response\")[-1].strip()\n",
    "\n",
    "dpo_model = dpo_trainer.model\n",
    "\n",
    "comparisons = []\n",
    "for title, content in cfg.eval_prompts:\n",
    "    base_out = generate(baseline_model, tokenizer, title, content)\n",
    "    dpo_out = generate(dpo_model, tokenizer, title, content)\n",
    "    comparisons.append({\n",
    "        \"prompt\": f\"{title} :: {content[:60]}...\",\n",
    "        \"base\": base_out,\n",
    "        \"dpo\": dpo_out,\n",
    "        \"base_len\": len(base_out),\n",
    "        \"dpo_len\": len(dpo_out)\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(comparisons)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a131d",
   "metadata": {},
   "source": [
    "## (선택) 8) Ollama `llama3.1:8b-instruct`와 간단 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests, os\n",
    "\n",
    "OLLAMA_HOST = os.getenv('OLLAMA_HOST', 'http://localhost:11434')\n",
    "OLLAMA_MODEL = os.getenv('OLLAMA_MODEL', 'llama3.1:8b-instruct')\n",
    "\n",
    "def ollama_generate(prompt, model=OLLAMA_MODEL, host=OLLAMA_HOST):\n",
    "    try:\n",
    "        resp = requests.post(f\"{host}/api/generate\", json={\"model\": model, \"prompt\": prompt, \"stream\": False}, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json().get(\"response\",\"\").strip()\n",
    "    except Exception as e:\n",
    "        print(\"Ollama 요청 실패:\", e)\n",
    "        return None\n",
    "\n",
    "print(\"Ollama 비교 예시 실행…\")\n",
    "for title, content in cfg.eval_prompts[:2]:\n",
    "    p = build_prompt(title, content)\n",
    "    o = ollama_generate(p)\n",
    "    if o:\n",
    "        print(\"\\n--- Ollama ---\")\n",
    "        print(o[:800])\n",
    "    else:\n",
    "        print(\"⚠️ Ollama 서버 또는 모델 준비 상태를 확인하세요.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708127ab",
   "metadata": {},
   "source": [
    "## 9) 비교 결과 CSV 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea62e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, time\n",
    "csv_path = cfg.out_dir / f\"compare_base_vs_dpo_{int(time.time())}.csv\"\n",
    "pd.DataFrame(comparisons).to_csv(csv_path, index=False, encoding='utf-8')\n",
    "print(\"Saved:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05b0fb",
   "metadata": {},
   "source": [
    "## (선택) 10) Langfuse 로깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY:\n",
    "    try:\n",
    "        from langfuse import Langfuse\n",
    "        lf = Langfuse(public_key=LANGFUSE_PUBLIC_KEY, secret_key=LANGFUSE_SECRET_KEY, host=LANGFUSE_HOST)\n",
    "        tr = lf.trace(name=\"week07_dpo\")\n",
    "        tr.generation(name=\"config\", metadata={\"beta\": cfg.beta, \"lr\": cfg.lr, \"max_length\": cfg.max_length})\n",
    "        for r in comparisons:\n",
    "            tr.event(name=\"compare\", input=r[\"prompt\"], output=r[\"dpo\"], metadata={\"base_len\": r[\"base_len\"], \"dpo_len\": r[\"dpo_len\"]})\n",
    "        tr.end()\n",
    "        print(\"Logged to Langfuse.\")\n",
    "    except Exception as e:\n",
    "        print(\"Langfuse 로깅 실패:\", e)\n",
    "else:\n",
    "    print(\"Langfuse 키가 없어 로깅 생략.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecc860",
   "metadata": {},
   "source": [
    "\n",
    "## 11) 로컬 실행 팁\n",
    "\n",
    "- **GPU 권장**: 4bit(QLoRA)로 1B급 모델은 8–12GB VRAM에서도 동작합니다.\n",
    "- **CPU만**: 작은 모델로만 실습(속도 느림). 스텝 수/배치/길이 최소화.\n",
    "- **OOM**: `max_length↓`, `per_device_train_batch_size↓`, `grad_accum_steps↑`, 8/4bit 사용.\n",
    "- **ref 모델**은 메모리 2배 소모 가능 → 기본값은 **ref-free**로 설정.\n",
    "- **템플릿 일관성**: 6주차와 동일 템플릿을 유지해야 전후 비교가 공정합니다.\n",
    "- **데이터 품질**: 역선호·모호쌍 제거, 길이 균형 유지가 핵심입니다.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
