{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a35958",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ‡°ğŸ‡· RAG Quick Lab (40â€‘min) â€” Pinecone + KorQuAD 2.0 (Beginner)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **í•œêµ­ì–´ RAG** ì‹¤ìŠµì„ ìœ„í•´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. (ëŒ€ìƒ: RAG ì²˜ìŒì¸ ëŒ€í•™ì›ìƒ)\n",
    "- **ì„ë² ë”©**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (384-dim, ë¹ ë¥´ê³  ê°€ë²¼ì›€)\n",
    "- **ë°ì´í„°ì…‹**: KorQuAD 2.0 (ì¼ë¶€ ìƒ˜í”Œ) â€” í‘œÂ·ë¦¬ìŠ¤íŠ¸ê°€ í¬í•¨ëœ í•œêµ­ì–´ ìœ„í‚¤ ê¸°ë°˜ MRC ë°ì´í„°\n",
    "- **Vector DB**: Pinecone (Serverless Index)\n",
    "\n",
    "> ì‹¤í–‰ ì „ ì¤€ë¹„ë¬¼\n",
    "> 1. Python â‰¥ 3.9 (ê¶Œì¥ 3.10+)\n",
    "> 2. (ì„ íƒ) ê°€ìƒí™˜ê²½ ìƒì„± í›„ í™œì„±í™”\n",
    "> 3. **Pinecone** API Key ë°œê¸‰ â†’ í™˜ê²½ë³€ìˆ˜ `PINECONE_API_KEY` ì§€ì •\n",
    "\n",
    "ì°¸ê³ :\n",
    "- KorQuAD 2.0: https://korquad.github.io/\n",
    "- Pinecone Quickstart: https://docs.pinecone.io/guides/indexes/create-an-index\n",
    "- RAG í‰ê°€(RAGAS): https://docs.ragas.io/  (ì´ë²ˆ ë©ì—ì„œëŠ” ê°„ë‹¨ í‰ê°€ë§Œ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8611d1",
   "metadata": {},
   "source": [
    "## 0. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dde3290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ragas 0.3.5 requires datasets>=4.0.0, but you have datasets 2.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (Colab or local) â€” ì¸í„°ë„· ì—°ê²° í•„ìš”\n",
    "!pip -q install \"pinecone-client>=5,<6\" \"sentence-transformers>=2.4,<3\" \"datasets>=2.19,<3\" \"tqdm>=4.66,<5\" \"python-dotenv>=1.0,<2\"\n",
    "# RAG í‰ê°€ê¹Œì§€ í•˜ë ¤ë©´ (ì„ íƒ)\n",
    "!pip -q install \"ragas>=0.1.14\" \"pandas>=2.1,<3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49afc5",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ë³€ìˆ˜ / ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af29f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, uuid, time, math, random, re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envì— PINECONE_API_KEY=... ë„£ì–´ë‘ë©´ ìë™ ë¡œë“œ\n",
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise RuntimeError(\"í™˜ê²½ë³€ìˆ˜ PINECONE_API_KEY ê°€ ì—†ìŠµë‹ˆë‹¤. Pinecone ì½˜ì†”ì—ì„œ ë°œê¸‰ í›„ ì„¤ì •í•˜ì„¸ìš”. (export PINECONE_API_KEY=...)\")\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c82bd0",
   "metadata": {},
   "source": [
    "## 2. Pinecone ì´ˆê¸°í™” ë° ì¸ë±ìŠ¤ ìƒì„± (Serverless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12015d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Creating index: rag-korquad-demo\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# ì¥ì†ŒëŠ” ë¬¸ì„œ ê¸°ì¤€ ì˜ˆì‹œì…ë‹ˆë‹¤. (ìš”ê¸ˆ/ë¦¬ì „ì€ ê³„ì • ì½˜ì†”ì—ì„œ í™•ì¸)\n",
    "CLOUD = \"aws\"          # ë˜ëŠ” \"gcp\",\"azure\" (ê³„ì •/ìš”ê¸ˆì œ í™•ì¸)\n",
    "REGION = \"us-east-1\"   # ì˜ˆ: \"us-east-1\", \"us-west-2\", \"eu-west-1\", \"us-east-1-aws\" ë“± ì½˜ì†” ê¶Œì¥ ë¦¬ì „\n",
    "INDEX_NAME = \"rag-korquad-demo\"\n",
    "\n",
    "EMBED_DIM = 384  # MiniLM-L12-v2 ì„ë² ë”© ì°¨ì›\n",
    "METRIC = \"cosine\"\n",
    "\n",
    "# ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if INDEX_NAME not in [idx[\"name\"] for idx in pc.list_indexes()]:\n",
    "    print(f\"â³ Creating index: {INDEX_NAME}\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=EMBED_DIM,\n",
    "        metric=METRIC,\n",
    "        spec=ServerlessSpec(cloud=CLOUD, region=REGION),\n",
    "        # ServerlessëŠ” pod íƒ€ì… ë¯¸ì§€ì •\n",
    "    )\n",
    "    # ì¸ë±ìŠ¤ ì¤€ë¹„ ëŒ€ê¸° (ê°„ë‹¨ ëŒ€ê¸°)\n",
    "    time.sleep(10)\n",
    "else:\n",
    "    print(f\"â„¹ï¸ Index already exists: {INDEX_NAME}\")\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(index.describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a39b4a",
   "metadata": {},
   "source": [
    "## 3. KorQuAD 2.0 ìƒ˜í”Œ ë¡œë“œ & ì²­í¬ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5f019",
   "metadata": {},
   "source": [
    "\n",
    "- ë³¸ ì‹¤ìŠµì€ **Hugging Face Datasets**ì˜ ì»¤ë®¤ë‹ˆí‹° ì—…ë¡œë“œëœ *KorQuAD 2.0* ë¯¸ëŸ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì— ë”°ë¼ ë¡œë”©ì´ ì§€ì—°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- í‘œ/ë¦¬ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê¸´ ë¬¸ì„œ íŠ¹ì„±ìƒ, **ë¬¸ë‹¨ ë‹¨ìœ„ ì²­í¬ + ì‚´ì§ ê²¹ì¹¨** ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26f5a737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'ìœ ëŸ½ì°Œë¥´ë ˆê¸°ì˜ ìš¸ìŒ ì†Œë¦¬ì™€ ë¹„ìŠ·í•œ ì¡°ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€?', 'answer': 'ìˆ˜íƒ‰', 'text': '## ì§ˆë¬¸: ìœ ëŸ½ì°Œë¥´ë ˆê¸°ì˜ ìš¸ìŒ ì†Œë¦¬ì™€ ë¹„ìŠ·í•œ ì¡°ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€?\\n## ë‹µë³€: ìˆ˜íƒ‰\\n\\n', 'context': '## ì§ˆë¬¸: ìœ ëŸ½ì°Œë¥´ë ˆê¸°ì˜ ìš¸ìŒ ì†Œë¦¬ì™€ ë¹„ìŠ·í•œ ì¡°ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€?\\n## ë‹µë³€: ìˆ˜íƒ‰', 'raw_text': '## ì§ˆë¬¸: ìœ ëŸ½ì°Œë¥´ë ˆê¸°ì˜ ìš¸ìŒ ì†Œë¦¬ì™€ ë¹„ìŠ·í•œ ì¡°ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€?\\n## ë‹µë³€: ìˆ˜íƒ‰\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_REPO = \"leeseeun/KorQuAD_2.0\"\n",
    "raw = load_dataset(DATASET_REPO, split=\"train\")\n",
    "\n",
    "Q_PAT = re.compile(r\"^[#\\s]*ì§ˆë¬¸\\s*:\\s*(.+?)\\s*$\", re.IGNORECASE | re.MULTILINE)\n",
    "A_PAT = re.compile(r\"^[#\\s]*ë‹µë³€\\s*:\\s*(.+?)\\s*$\", re.IGNORECASE | re.MULTILINE)\n",
    "\n",
    "def _extract_qna_from_text(text: str):\n",
    "    q = a = \"\"\n",
    "    if not text: \n",
    "        return q, a\n",
    "    mq = Q_PAT.search(text)\n",
    "    ma = A_PAT.search(text)\n",
    "    if mq: q = mq.group(1).strip()\n",
    "    if ma: a = ma.group(1).strip()\n",
    "    return q, a\n",
    "\n",
    "def normalize_sample(x):\n",
    "    # 1) ê¸°ë³¸ í‚¤\n",
    "    q = x.get(\"question\") or x.get(\"Question\") or x.get(\"questions\") or \"\"\n",
    "    ctx = x.get(\"context\")  or x.get(\"Context\")  or x.get(\"article\")   or \"\"\n",
    "    ans = \"\"\n",
    "    txt = x.get(\"text\") or \"\"\n",
    "\n",
    "    # 2) KorQuAD answers dict\n",
    "    answers = x.get(\"answers\")\n",
    "    if isinstance(answers, dict):\n",
    "        ans_list = answers.get(\"text\", [])\n",
    "        if isinstance(ans_list, list) and ans_list:\n",
    "            ans = (ans_list[0] or \"\").strip()\n",
    "\n",
    "    # 3) â˜… ì»¨í…ìŠ¤íŠ¸ í´ë°±: contextê°€ ë¹„ì–´ ìˆìœ¼ë©´ textì—ì„œ íŒŒì‹± (ì§ˆë¬¸ ìœ ë¬´ì™€ ë¬´ê´€)\n",
    "    if not ctx and txt:\n",
    "        q2, a2 = _extract_qna_from_text(txt)\n",
    "        # ì§ˆë¬¸/ì •ë‹µì´ ë¹„ì–´ìˆë‹¤ë©´ ë³´ì¡°ë¡œ ì±„ì›Œì¤Œ\n",
    "        if not q and q2: \n",
    "            q = q2\n",
    "        if not ans and a2:\n",
    "            ans = a2\n",
    "\n",
    "        # RAGìš© ì»¨í…ìŠ¤íŠ¸: Q/A ë¼ì¸ì„ ì œê±°í•œ ë‚˜ë¨¸ì§€ ì „ì²´\n",
    "        ctx_candidate = re.sub(r\"^[#\\s]*ì§ˆë¬¸\\s*:.+$\", \"\", txt, flags=re.MULTILINE)\n",
    "        ctx_candidate = re.sub(r\"^[#\\s]*ë‹µë³€\\s*:.+$\", \"\", ctx_candidate, flags=re.MULTILINE).strip()\n",
    "\n",
    "        # ë§Œì•½ ì œê±°í•˜ê³  ë‚˜ë‹ˆ ì§„ì§œë¡œ ë‚¨ëŠ” ê²Œ ì—†ë‹¤ë©´, ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ txt ì „ì²´ë¥¼ ì‚¬ìš©\n",
    "        ctx = ctx_candidate if ctx_candidate else txt\n",
    "\n",
    "    # ë°©ì–´ì  ì •ë¦¬\n",
    "    q   = str(q or \"\").strip()\n",
    "    ctx = str(ctx or \"\").strip()\n",
    "    ans = str(ans or \"\").strip()\n",
    "    return {\"question\": q, \"context\": ctx, \"answer\": ans, \"raw_text\": txt}\n",
    "\n",
    "dataset = raw.map(normalize_sample)\n",
    "dataset = dataset.shuffle(seed=42).select(range(min(300, len(dataset))))\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc6da7",
   "metadata": {},
   "source": [
    "### 3â€‘1. ê°„ë‹¨ ì²­í¬ í•¨ìˆ˜ (ë¬¸ë‹¨ ê¸°ë°˜ + ê²¹ì¹¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea7dd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(corpus) = 301 | skipped(no context) = 0\n",
      "preview: doc-0-chunk-0 ## ì§ˆë¬¸: ìœ ëŸ½ì°Œë¥´ë ˆê¸°ì˜ ìš¸ìŒ ì†Œë¦¬ì™€ ë¹„ìŠ·í•œ ì¡°ë¥˜ëŠ” ë¬´ì—‡ì¸ê°€?\n",
      "## ë‹µë³€: ìˆ˜íƒ‰\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def paragraph_chunk(text: str, max_chars=800, overlap_chars=120):\n",
    "    if not text:\n",
    "        return []\n",
    "    paras = [p.strip() for p in re.split(r'(?:\\r?\\n){2,}', text) if p.strip()]\n",
    "    if not paras:\n",
    "        paras = [text.strip()]\n",
    "    chunks = []\n",
    "    for p in paras:\n",
    "        if len(p) <= max_chars:\n",
    "            chunks.append(p)\n",
    "        else:\n",
    "            start = 0\n",
    "            while start < len(p):\n",
    "                end = min(start + max_chars, len(p))\n",
    "                chunks.append(p[start:end])\n",
    "                if end >= len(p):\n",
    "                    break\n",
    "                start = max(0, end - overlap_chars)\n",
    "    return chunks\n",
    "\n",
    "corpus = []\n",
    "skipped = 0\n",
    "for i, row in enumerate(dataset):\n",
    "    ctx = row[\"context\"]\n",
    "    if not ctx:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    for j, ch in enumerate(paragraph_chunk(ctx)):\n",
    "        corpus.append({\n",
    "            \"id\": f\"doc-{i}-chunk-{j}\",\n",
    "            \"text\": ch,\n",
    "            \"meta\": {\n",
    "                \"source\": \"KorQuAD2.0-mirror\",\n",
    "                \"doc_id\": f\"doc-{i}\",\n",
    "                \"chunk_id\": j,\n",
    "                \"language\": \"ko\",\n",
    "                \"has_true_context\": bool(row[\"raw_text\"] and row[\"context\"] != \"\")\n",
    "            }\n",
    "        })\n",
    "\n",
    "print(\"len(corpus) =\", len(corpus), \"| skipped(no context) =\", skipped)\n",
    "if corpus:\n",
    "    print(\"preview:\", corpus[0][\"id\"], corpus[0][\"text\"][:120])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbca139",
   "metadata": {},
   "source": [
    "## 4. ì„ë² ë”© ìƒì„± & Pinecone ì—…ì„œíŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2626b7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Upsert ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "import itertools\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "def batched(iterable, n=64):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        batch = list(itertools.islice(it, n))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch\n",
    "\n",
    "if not corpus:\n",
    "    raise RuntimeError(\"corpusê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì• ë‹¨ê³„(ì •ê·œí™”/ì²­í¬)ì—ì„œ ctx í´ë°±ì´ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "for batch in tqdm(batched(corpus, 64), total=math.ceil(len(corpus)/64)):\n",
    "    texts = [b[\"text\"] for b in batch]\n",
    "    vecs = model.encode(texts, normalize_embeddings=True, show_progress_bar=False)\n",
    "    items = []\n",
    "    for b, v in zip(batch, vecs):\n",
    "        items.append({\n",
    "            \"id\": b[\"id\"],\n",
    "            \"values\": v.tolist(),\n",
    "            \"metadata\": {**b[\"meta\"], \"preview\": b[\"text\"][:200]}\n",
    "        })\n",
    "    # â˜… v5: vectors= ë¡œ ì „ë‹¬\n",
    "    index.upsert(vectors=items)  # (ì„ íƒ) namespace=\"default\"\n",
    "print(\"âœ… Upsert ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58244647",
   "metadata": {},
   "source": [
    "## 5. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ â€” í•œêµ­ì–´ ì§ˆë¬¸ìœ¼ë¡œ Topâ€‘k ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3335629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Q: ì£¼ë¯¼ë“±ë¡í‘œ ì´ˆë³¸ ë°œê¸‰ ìˆ˜ìˆ˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€?\n",
      " 1. score=0.465 | id=doc-189-chunk-0 | ## ì§ˆë¬¸: 2010ë…„ì— ë‚¨íƒœë ¹ì—­ì—ì„œ ìŠ¹ì°¨í•œ í•˜ë£¨ í‰ê·  ì¸ì›ì€ ëª‡ ëª…ì¼ê¹Œ?\n",
      "## ë‹µë³€: 1,316...\n",
      " 2. score=0.455 | id=doc-287-chunk-0 | ## ì§ˆë¬¸: 2005ë…„ê¹Œì§€ë§Œ í•´ë„ ì´ë¯¸ ì–¼ë§ˆë§Œí¼ì˜ ìê¸ˆì´ ë“¤ì—ˆìŠµë‹ˆê¹Œ?\n",
      "## ë‹µë³€: 130ì—¬ì–µì›...\n",
      " 3. score=0.431 | id=doc-261-chunk-0 | ## ì§ˆë¬¸: 2004ë…„ë¶€í„° 2009ë…„ê¹Œì§€ ê³ ë£Œì¹´ì¿  ì—­ì˜ ì—°ë„ë³„ í™”ë¬¼ëŸ‰ì€ ì–´ëŠ ì •ë„ì˜€ì„ê¹Œ?\n",
      "## ë‹µë³€:  ì—°ë„ ë³´ëƒ„ ë°›ìŒ í•©ê³„ ë¹„ê³  2004ë…„ 199,000 174...\n",
      " 4. score=0.416 | id=doc-60-chunk-0 | ## ì§ˆë¬¸: ì´ì„¸ì´ì‹œë°”ì‹œì—­ì—ì„œ ìŠ¹ì°¨í•˜ëŠ” í•˜ë£¨ í‰ê·  ì¸ì›ìˆ˜ê°€ 73ëª…ì¸ í•´ëŠ”?\n",
      "## ë‹µë³€: 2000ë…„...\n",
      " 5. score=0.402 | id=doc-41-chunk-0 | ## ì§ˆë¬¸: ë¡œê³  ê¸ˆì•¡ì´ ì–¼ë§ˆì•¼?\n",
      "## ë‹µë³€: 250ë§Œ ìœ ë¡œ...\n",
      "\n",
      "### Q: ìœ„ì„±í•­ë²•ì¥ì¹˜(GPS)ì˜ ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€?\n",
      " 1. score=0.386 | id=doc-242-chunk-0 | ## ì§ˆë¬¸: ì¼€í”ŒëŸ¬ ê´€ì¸¡ì„ ì„ í†µí•´ ì•Œê²Œ ëœ ì‚¬ì‹¤ë“¤ì—ëŠ” ì–´ë– í•œ ê²ƒë“¤ì´ ìˆìŠµë‹ˆê¹Œ?\n",
      "## ë‹µë³€: 2010ë…„ 6ì›” ì¼€í”ŒëŸ¬ ê´€ì¸¡ì„ ê³¼ í†µì‹ ì—°ê²°ì´ ì‹œì‘ëœ ì§€ 43ì¼ì´ ì§€ë‚œ ì‹œ...\n",
      " 2. score=0.370 | id=doc-104-chunk-0 | ## ì§ˆë¬¸: ë²¤êµ¬ë¦¬ì˜¨ êµ­ì œê³µí•­ì„ ìš´ì˜í•˜ëŠ” ê³³ì€ ì–´ë””ì•¼?\n",
      "## ë‹µë³€: ì´ìŠ¤ë¼ì—˜ ê³µí•­ ê³µì‚¬...\n",
      " 3. score=0.361 | id=doc-153-chunk-0 | ## ì§ˆë¬¸: ë¬´ê¸°ì¤‘ì—ì„œ ê³ ì¶œë ¥ ë¼ìŠ¤ê±´ì˜ íŠ¹ì§•ì—ëŠ” ì–´ë–¤ê²ƒë“¤ì´ ìˆì„ê¹Œ?\n",
      "## ë‹µë³€: ê°•ë ¥í•œ ëŒ€êµ¬ê²½ íƒ„í™˜ì„ ì‚¬ìš©í•œë‹¤. ë˜í•œ ì´ê²€ì„ ë¶™ì—¬ë†¨ê¸° ë•Œë¬¸ì— ê·¼ì ‘ì „ì—ì„œ ìƒë‹¹í•œ ìœ„...\n",
      " 4. score=0.340 | id=doc-193-chunk-0 | ## ì§ˆë¬¸: ì§€í•˜ì²  2í˜¸ì„  í•œì–‘ëŒ€ì—­ê³¼ êµë‚´ ë³¸ê´€ ì• ì—°ê²°í†µë¡œì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€? \n",
      "## ë‹µë³€: ì• ì§€ë¬¸...\n",
      " 5. score=0.332 | id=doc-94-chunk-0 | ## ì§ˆë¬¸: TMT ì‚¬ê°€ ì—ì´ ìœ„ì¼ í˜¸ë¥¼ ì–´ë– í•œ ë°°ë¡œ ê°œì¡°í–ˆëŠ”ê°€?\n",
      "## ë‹µë³€: ê¸°ë¦„ì œê±°ì„ ...\n",
      "\n",
      "### Q: ëŒ€í•œë¯¼êµ­ êµ­íšŒì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€?\n",
      " 1. score=0.588 | id=doc-173-chunk-0 | ## ì§ˆë¬¸: 2005ë…„ ë‹¹ì‹œ ë°•ê·¼í˜œê°€ ì†Œì†í•œ ë‹¹ì€?\n",
      "## ë‹µë³€: í•œë‚˜ë¼ë‹¹...\n",
      " 2. score=0.567 | id=doc-232-chunk-0 | ## ì§ˆë¬¸: ê³„ì•½ ë§Œë£Œ í›„ì˜ ì´ë“ì— ëŒ€í•œ ë³´ìƒì²­êµ¬ë¥¼ ê·œì •í•˜ê³  ìˆëŠ” ì¡°í•­ì€ ëª‡í•­ì¸ê°€?\n",
      "## ë‹µë³€: ëŒ€í•œë¯¼êµ­ ìƒë²• ì œ92ì¡°ì˜2 ì œ1í•­...\n",
      " 3. score=0.557 | id=doc-163-chunk-0 | ## ì§ˆë¬¸: ì¶©ì²­ë¶ë„ì²­ì— ì†Œì†ëœ ê³µì§ê³¼ ê´€ë ¨ì´ ìˆëŠ” ë‹¨ì²´ ì¤‘ ì´ë¦„ì´ ê°€ì¥ ì§§ì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€?\n",
      "## ë‹µë³€: ì¶©ë¶í•™ì‚¬...\n",
      " 4. score=0.544 | id=doc-70-chunk-0 | ## ì§ˆë¬¸: ê¹€ì˜ì‚¼ ëŒ€í†µë ¹ì´ ì •ê¶Œì„ íšë“í•  ìˆ˜ ìˆì—ˆë˜ ì‚¬ê±´ì€?\n",
      "## ë‹µë³€: 3ë‹¹ í•©ë‹¹...\n",
      " 5. score=0.536 | id=doc-238-chunk-0 | ## ì§ˆë¬¸: ì„¸ì›”í˜¸ ì°¸ì‚¬ ë‹¹ì‹œ í˜„ì¥ì§€íœ˜ê´€ì˜ ì´ë¦„ì€?\n",
      "## ë‹µë³€: ê¹€ê²½ì¼...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEST_QUERIES = [\n",
    "    \"ì£¼ë¯¼ë“±ë¡í‘œ ì´ˆë³¸ ë°œê¸‰ ìˆ˜ìˆ˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€?\",\n",
    "    \"ìœ„ì„±í•­ë²•ì¥ì¹˜(GPS)ì˜ ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€?\",\n",
    "    \"ëŒ€í•œë¯¼êµ­ êµ­íšŒì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€?\",\n",
    "]\n",
    "\n",
    "def search(query: str, top_k=5):\n",
    "    qv = model.encode([query], normalize_embeddings=True)[0].tolist()\n",
    "    res = index.query(vector=qv, top_k=top_k, include_metadata=True)\n",
    "    return res\n",
    "\n",
    "for q in TEST_QUERIES:\n",
    "    print(\"\\n### Q:\", q)\n",
    "    res = search(q, top_k=5)\n",
    "    for i, match in enumerate(res[\"matches\"]):\n",
    "        score = match[\"score\"]\n",
    "        meta = match.get(\"metadata\", {})\n",
    "        preview = meta.get(\"preview\", \"\")\n",
    "        print(f\"{i+1:>2}. score={score:.3f} | id={match['id']} | {preview[:90]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1702d7",
   "metadata": {},
   "source": [
    "### 5â€‘1. (ì˜µì…˜) ê°„ì´ ìƒì„± í…œí”Œë¦¿ â€” LLM ì—†ì´ ìŠ¤ë‹ˆí« ê¸°ë°˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "974cca60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: ì£¼ë¯¼ë“±ë¡í‘œ ì´ˆë³¸ ë°œê¸‰ ìˆ˜ìˆ˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€?\n",
      "\n",
      "ì•„ë˜ ê·¼ê±° ìŠ¤ë‹ˆí«ì„ ì°¸ê³ í•˜ì„¸ìš”:\n",
      "## ì§ˆë¬¸: 2010ë…„ì— ë‚¨íƒœë ¹ì—­ì—ì„œ ìŠ¹ì°¨í•œ í•˜ë£¨ í‰ê·  ì¸ì›ì€ ëª‡ ëª…ì¼ê¹Œ?\n",
      "## ë‹µë³€: 1,316\n",
      "---\n",
      "## ì§ˆë¬¸: 2005ë…„ê¹Œì§€ë§Œ í•´ë„ ì´ë¯¸ ì–¼ë§ˆë§Œí¼ì˜ ìê¸ˆì´ ë“¤ì—ˆìŠµë‹ˆê¹Œ?\n",
      "## ë‹µë³€: 130ì—¬ì–µì›\n",
      "---\n",
      "## ì§ˆë¬¸: 2004ë…„ë¶€í„° 2009ë…„ê¹Œì§€ ê³ ë£Œì¹´ì¿  ì—­ì˜ ì—°ë„ë³„ í™”ë¬¼ëŸ‰ì€ ì–´ëŠ ì •ë„ì˜€ì„ê¹Œ?\n",
      "## ë‹µë³€:  ì—°ë„ ë³´ëƒ„ ë°›ìŒ í•©ê³„ ë¹„ê³  2004ë…„ 199,000 174,000 373,000 2005ë…„ 199,000 159,000 358,000 2006ë…„ 205,000 156,000 361,000 2007ë…„ 187,000 148,000 335,000 2008ë…„ 1\n",
      "---\n",
      "## ì§ˆë¬¸: ì´ì„¸ì´ì‹œë°”ì‹œì—­ì—ì„œ ìŠ¹ì°¨í•˜ëŠ” í•˜ë£¨ í‰ê·  ì¸ì›ìˆ˜ê°€ 73ëª…ì¸ í•´ëŠ”?\n",
      "## ë‹µë³€: 2000ë…„\n",
      "---\n",
      "## ì§ˆë¬¸: ë¡œê³  ê¸ˆì•¡ì´ ì–¼ë§ˆì•¼?\n",
      "## ë‹µë³€: 250ë§Œ ìœ ë¡œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def answer_with_snippets(query: str, top_k=5):\n",
    "    res = search(query, top_k=top_k)\n",
    "    snippets = [m[\"metadata\"][\"preview\"] for m in res[\"matches\"]]\n",
    "    ans = f\"ì§ˆë¬¸: {query}\\n\\nì•„ë˜ ê·¼ê±° ìŠ¤ë‹ˆí«ì„ ì°¸ê³ í•˜ì„¸ìš”:\\n\" + \"\\n---\\n\".join(snippets)\n",
    "    return ans\n",
    "\n",
    "print(answer_with_snippets(\"ì£¼ë¯¼ë“±ë¡í‘œ ì´ˆë³¸ ë°œê¸‰ ìˆ˜ìˆ˜ë£ŒëŠ” ì–¼ë§ˆì¸ê°€?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19711f24",
   "metadata": {},
   "source": [
    "## 6. ê°„ë‹¨í•œ Retrieval í’ˆì§ˆ ì¸¡ì • (Recall@k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12869c",
   "metadata": {},
   "source": [
    "\n",
    "- **ì•„ì´ë””ì–´**: KorQuAD ì •ë‹µ ë¬¸ìì—´ì´ í¬í•¨ëœ ì²­í¬ê°€ Topâ€‘kì— ë“¤ì–´ì˜¤ë©´ **ì •ë‹µì„ ì°¾ì€ ê²ƒ**ìœ¼ë¡œ ê°„ì£¼\n",
    "- ì£¼ì˜: ì‹¤ì œ í‰ê°€ëŠ” í† í°í™”/ì •ê·œí™”, ë¶€ë¶„ì¼ì¹˜, ë¼ë²¨ë§ ì˜¤ë¥˜ ë“±ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. (ì—¬ê¸°ì„  ê°„ë‹¨ ë²„ì „)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f89fbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:13<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 (ë‹¨ìˆœ í¬í•¨ ê²€ì‚¬ ê¸°ì¤€) = 82.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recall_at_k(samples, k=5, n_eval=50):\n",
    "    # ë¬´ì‘ìœ„ ì§ˆë¬¸ n_evalê°œ ìƒ˜í”Œë§\n",
    "    samp = random.sample(list(range(len(samples))), min(n_eval, len(samples)))\n",
    "    hits = 0\n",
    "    for i in tqdm(samp):\n",
    "        row = samples[i]\n",
    "        q, ans = row[\"question\"], (row[\"answer\"] or \"\").strip()\n",
    "        if not ans: \n",
    "            continue\n",
    "        res = search(q, top_k=k)\n",
    "        top_texts = [m[\"metadata\"].get(\"preview\",\"\") for m in res[\"matches\"]]\n",
    "        # ë§¤ìš° ë‹¨ìˆœí•œ í¬í•¨ ê²€ì‚¬\n",
    "        if any(ans in t for t in top_texts):\n",
    "            hits += 1\n",
    "    return hits / max(1, len(samp))\n",
    "\n",
    "r5 = recall_at_k(dataset, k=5, n_eval=50)\n",
    "print(f\"Recall@5 (ë‹¨ìˆœ í¬í•¨ ê²€ì‚¬ ê¸°ì¤€) = {r5:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d3cdc",
   "metadata": {},
   "source": [
    "## 7. (ì„ íƒ) ì •ë¦¬ â€” ì¸ë±ìŠ¤ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ì‹¤ìŠµ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ ì›í•  ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "# pc.delete_index(INDEX_NAME)\n",
    "# print(\"ğŸ§¹ Index deleted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fdede3",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Appendix â€” Notes & Links\n",
    "\n",
    "- **KorQuAD 2.0**  \n",
    "  - í™ˆí˜ì´ì§€: https://korquad.github.io/\n",
    "  - (ì»¤ë®¤ë‹ˆí‹° ë¯¸ëŸ¬) Hugging Face: ì˜ˆ) https://huggingface.co/datasets/leeseeun/KorQuAD_2.0\n",
    "- **Pinecone**  \n",
    "  - Create Serverless Index: https://docs.pinecone.io/guides/indexes/create-an-index\n",
    "- **í‰ê°€**  \n",
    "  - RAGAS: https://docs.ragas.io/ (ì´ë²ˆ ë©ì€ ë‹¨ìˆœ Recall@kë§Œ ì˜ˆì‹œ)\n",
    "\n",
    "ê¶Œì¥ ê³¼ì œ ì•„ì´ë””ì–´:\n",
    "1) **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: BM25(ì˜ˆ: `rank-bm25`) ê²°ê³¼ì™€ Cosineì„ RRFë¡œ ìœµí•©í•´ Topâ€‘k ë¹„êµ\n",
    "2) **ë¦¬ë­í¬**: ìƒìœ„ N ìŠ¤ë‹ˆí«ì„ Cross-Encoderë¡œ ì¬ì ìˆ˜í™” (Cohere Rerank, Sentence-Transformers cross-encoder ë“±)\n",
    "3) **ë©”íƒ€ í•„í„°**: `language='ko'`, `source='KorQuAD2.0'` ë“± í•„ë“œë¡œ í•„í„°ë§ â†’ í’ˆì§ˆ/ì†ë„ ë¹„êµ\n",
    "4) **ì²­í¬ ì „ëµ ë¹„êµ**: ì²­í¬ í¬ê¸°/ê²¹ì¹¨ì„ ë‹¬ë¦¬í•˜ì—¬ Recall@k ë³€í™”ë¥¼ ì¸¡ì •\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ajou-llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
